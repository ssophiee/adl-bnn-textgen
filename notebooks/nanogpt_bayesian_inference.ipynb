{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "524b7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torchopt\n",
    "import posteriors\n",
    "\n",
    "# Add paths for importing utilities and models\n",
    "current_dir = Path.cwd()\n",
    "sys.path.append(str(current_dir))\n",
    "sys.path.append(str(current_dir.parent))\n",
    "sys.path.append(str(current_dir.parent / \"baselines\"))\n",
    "\n",
    "\n",
    "from src.nanogpt_utils import load_model, load_tokenizer, encode, decode\n",
    "from src.bayesian_utils import create_training_batches, run_bayesian_pipeline\n",
    "from config import CONFIG, MODEL_PATH, META_PATH, DATA_DIR\n",
    "\n",
    "for path in [MODEL_PATH, META_PATH, DATA_DIR]:\n",
    "    assert path.exists(), f\"Path {path} does not exist.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872a882",
   "metadata": {},
   "source": [
    "#### Load pre-trained baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e218ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model arguments: {'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'block_size': 256, 'bias': False, 'vocab_size': 65, 'dropout': 0.2}\n",
      "number of parameters: 10.65M\n",
      "Model loaded successfully!\n",
      "Number of parameters: 10,745,088\n",
      "Running character-level model\n"
     ]
    }
   ],
   "source": [
    "model, checkpoint = load_model(Path(MODEL_PATH))\n",
    "    \n",
    "# Load tokenizer and vocabulary size\n",
    "stoi, itos = load_tokenizer(Path(META_PATH))\n",
    "vocab_size = len(itos)\n",
    "\n",
    "# Extract model parameters for posteriors\n",
    "params = dict(model.named_parameters())\n",
    "\n",
    "if vocab_size == 65:\n",
    "    print(\"Running character-level model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d60483",
   "metadata": {},
   "source": [
    "#### Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "415823e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 32 training batches\n",
      "Batch shape: torch.Size([16, 128])\n",
      "Target shape: torch.Size([16, 1])\n",
      "Total training samples: 500\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data for Bayesian inference\n",
    "train_data_path = Path(DATA_DIR / 'train.bin')\n",
    "data = np.memmap(str(train_data_path), dtype=np.uint16, mode='r')\n",
    "\n",
    "training_batches = create_training_batches(\n",
    "    data, \n",
    "    CONFIG['batch_size'], \n",
    "    CONFIG['max_seq_length'], \n",
    "    CONFIG['train_samples']\n",
    ")\n",
    "\n",
    "print(f\"Created {len(training_batches)} training batches\")\n",
    "print(f\"Batch shape: {training_batches[0][0].shape}\")\n",
    "print(f\"Target shape: {training_batches[0][1].shape}\")\n",
    "\n",
    "# Calculate number of data points for posteriors\n",
    "num_data = CONFIG['train_samples']\n",
    "print(f\"Total training samples: {num_data}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13928dc",
   "metadata": {},
   "source": [
    "#### Setup Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c00df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with minimal config\n",
    "test_config = CONFIG.copy()\n",
    "test_config['num_epochs'] = 1\n",
    "test_config['train_samples'] = 32  # Just 2 batches worth\n",
    "\n",
    "# Create smaller test batches\n",
    "test_batches = create_training_batches(\n",
    "    data, \n",
    "    test_config['batch_size'], \n",
    "    test_config['max_seq_length'], \n",
    "    test_config['train_samples']\n",
    ")\n",
    "\n",
    "print(f\"Test run with {len(test_batches)} batches, {test_config['num_epochs']} epoch\")\n",
    "print(\"This should complete quickly if the fix is working...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfca9637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Setting up VI sampler\n",
      "============================================================\n",
      "VI configured with:\n",
      "- Learning rate: 5e-06\n",
      "- Temperature: 0.001\n",
      "- Samples per update: 1\n",
      "\n",
      "============================================================\n",
      "Starting Bayesian Training with VI\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Epochs: 3\n",
      "  - Batches per epoch: 32\n",
      "  - Total iterations: 96\n",
      "============================================================\n",
      "\n",
      "Epoch 1/3\n",
      "------------------------------------------------------------\n",
      "VI configured with:\n",
      "- Learning rate: 5e-06\n",
      "- Temperature: 0.001\n",
      "- Samples per update: 1\n",
      "\n",
      "============================================================\n",
      "Starting Bayesian Training with VI\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Epochs: 3\n",
      "  - Batches per epoch: 32\n",
      "  - Total iterations: 96\n",
      "============================================================\n",
      "\n",
      "Epoch 1/3\n",
      "------------------------------------------------------------\n",
      "NLL computed successfully: 67.66502380371094\n",
      "NLL computed successfully: 67.66502380371094\n",
      "Log prior computed successfully: -15255060.0\n",
      "Log posterior computed successfully: -30577.783203125\n",
      "Log prior computed successfully: -15255060.0\n",
      "Log posterior computed successfully: -30577.783203125\n",
      "NLL computed successfully: 1.8471720218658447\n",
      "NLL computed successfully: 1.8471720218658447\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19764.115234375\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19764.115234375\n",
      "NLL computed successfully: 71.53680419921875\n",
      "Log prior computed successfully: -15260519.0\n",
      "Log posterior computed successfully: -30592.57421875\n",
      "NLL computed successfully: 71.53680419921875\n",
      "Log prior computed successfully: -15260519.0\n",
      "Log posterior computed successfully: -30592.57421875\n",
      "NLL computed successfully: 1.2240663766860962\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.4921875\n",
      "NLL computed successfully: 1.2240663766860962\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.4921875\n",
      "NLL computed successfully: 60.396907806396484\n",
      "Log prior computed successfully: -15253848.0\n",
      "Log posterior computed successfully: -30568.091796875\n",
      "NLL computed successfully: 60.396907806396484\n",
      "Log prior computed successfully: -15253848.0\n",
      "Log posterior computed successfully: -30568.091796875\n",
      "NLL computed successfully: 1.1917787790298462\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.458984375\n",
      "NLL computed successfully: 1.1917787790298462\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.458984375\n",
      "NLL computed successfully: 82.851318359375\n",
      "Log prior computed successfully: -15252948.0\n",
      "Log posterior computed successfully: -30588.748046875\n",
      "NLL computed successfully: 82.851318359375\n",
      "Log prior computed successfully: -15252948.0\n",
      "Log posterior computed successfully: -30588.748046875\n",
      "NLL computed successfully: 1.0992553234100342\n",
      "Log prior computed successfully: -9881133.0\n",
      "Log posterior computed successfully: -19763.365234375\n",
      "NLL computed successfully: 1.0992553234100342\n",
      "Log prior computed successfully: -9881133.0\n",
      "Log posterior computed successfully: -19763.365234375\n",
      "NLL computed successfully: 88.75929260253906\n",
      "Log prior computed successfully: -15258259.0\n",
      "Log posterior computed successfully: -30605.27734375\n",
      "NLL computed successfully: 88.75929260253906\n",
      "Log prior computed successfully: -15258259.0\n",
      "Log posterior computed successfully: -30605.27734375\n",
      "NLL computed successfully: 0.6477830410003662\n",
      "Log prior computed successfully: -9881133.0\n",
      "Log posterior computed successfully: -19762.9140625\n",
      "NLL computed successfully: 0.6477830410003662\n",
      "Log prior computed successfully: -9881133.0\n",
      "Log posterior computed successfully: -19762.9140625\n",
      "NLL computed successfully: 53.4439811706543\n",
      "Log prior computed successfully: -15253320.0\n",
      "Log posterior computed successfully: -30560.083984375\n",
      "NLL computed successfully: 53.4439811706543\n",
      "Log prior computed successfully: -15253320.0\n",
      "Log posterior computed successfully: -30560.083984375\n",
      "NLL computed successfully: 1.6132508516311646\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.880859375\n",
      "  [  6/32] Loss: 1.1781 | Log Post: -19763.4223\n",
      "NLL computed successfully: 1.6132508516311646\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.880859375\n",
      "  [  6/32] Loss: 1.1781 | Log Post: -19763.4223\n",
      "NLL computed successfully: 70.0645523071289\n",
      "NLL computed successfully: 70.0645523071289\n",
      "Log prior computed successfully: -15252165.0\n",
      "Log posterior computed successfully: -30574.39453125\n",
      "Log prior computed successfully: -15252165.0\n",
      "Log posterior computed successfully: -30574.39453125\n",
      "NLL computed successfully: 1.033230185508728\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.30078125\n",
      "NLL computed successfully: 1.033230185508728\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.30078125\n",
      "NLL computed successfully: 70.8960952758789\n",
      "Log prior computed successfully: -15252438.0\n",
      "Log posterior computed successfully: -30575.7734375\n",
      "NLL computed successfully: 70.8960952758789\n",
      "Log prior computed successfully: -15252438.0\n",
      "Log posterior computed successfully: -30575.7734375\n",
      "NLL computed successfully: 1.6046113967895508\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.873046875\n",
      "NLL computed successfully: 1.6046113967895508\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.873046875\n",
      "NLL computed successfully: 63.13896179199219\n",
      "Log prior computed successfully: -15256088.0\n",
      "Log posterior computed successfully: -30575.314453125\n",
      "NLL computed successfully: 63.13896179199219\n",
      "Log prior computed successfully: -15256088.0\n",
      "Log posterior computed successfully: -30575.314453125\n",
      "NLL computed successfully: 0.9592369794845581\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.2265625\n",
      "NLL computed successfully: 0.9592369794845581\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.2265625\n",
      "NLL computed successfully: 75.30160522460938\n",
      "Log prior computed successfully: -15254797.0\n",
      "Log posterior computed successfully: -30584.89453125\n",
      "NLL computed successfully: 75.30160522460938\n",
      "Log prior computed successfully: -15254797.0\n",
      "Log posterior computed successfully: -30584.89453125\n",
      "NLL computed successfully: 1.8381627798080444\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19764.10546875\n",
      "NLL computed successfully: 1.8381627798080444\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19764.10546875\n",
      "NLL computed successfully: 74.87648010253906\n",
      "Log prior computed successfully: -15253237.0\n",
      "Log posterior computed successfully: -30581.3515625\n",
      "NLL computed successfully: 74.87648010253906\n",
      "Log prior computed successfully: -15253237.0\n",
      "Log posterior computed successfully: -30581.3515625\n",
      "NLL computed successfully: 1.174409031867981\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19763.44140625\n",
      "NLL computed successfully: 82.51283264160156\n",
      "Log prior computed successfully: -15250031.0\n",
      "Log posterior computed successfully: -30582.576171875\n",
      "NLL computed successfully: 2.124490261077881\n",
      "Log prior computed successfully: -9881134.0\n",
      "Log posterior computed successfully: -19764.392578125\n",
      "  [ 12/32] Loss: 1.4861 | Log Post: -19763.8078\n",
      "NLL computed successfully: 60.05754089355469\n",
      "Log prior computed successfully: -15252369.0\n",
      "Log posterior computed successfully: -30564.794921875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m state_vi, metrics_vi, eval_vi = \u001b[43mrun_bayesian_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                                      \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvi\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                                      \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayk_\\OneDrive\\Desktop\\05_LMU_Masters\\04_applied_dl\\adl-bnn-textgen\\src\\bayesian_utils.py:715\u001b[39m, in \u001b[36mrun_bayesian_pipeline\u001b[39m\u001b[34m(training_batches, sampler_type, use_wandb)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    714\u001b[39m     transform, state = pipeline.setup_sampler(log_posterior_fn, params)\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     state, metrics = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43msingle_batch_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_posterior_fn\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m     \u001b[38;5;66;03m# Pass the model for deterministic comparison\u001b[39;00m\n\u001b[32m    721\u001b[39m     eval_results = pipeline.evaluate_predictions(\n\u001b[32m    722\u001b[39m         state, MODEL, training_batches[\u001b[32m0\u001b[39m], num_samples=\u001b[32m5\u001b[39m\n\u001b[32m    723\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayk_\\OneDrive\\Desktop\\05_LMU_Masters\\04_applied_dl\\adl-bnn-textgen\\src\\bayesian_utils.py:272\u001b[39m, in \u001b[36mBayesianSamplerPipeline.run_training\u001b[39m\u001b[34m(self, transform, state, training_batches, single_batch_loss, log_posterior_fn)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_batches):\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    271\u001b[39m         \u001b[38;5;66;03m# transform.update() returns (new_state, aux_data)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m         state, aux = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m         \u001b[38;5;66;03m# Extract params from state (should be VIDiagState or similar named tuple)\u001b[39;00m\n\u001b[32m    275\u001b[39m         current_params = state.params\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayk_\\OneDrive\\Desktop\\05_LMU_Masters\\04_applied_dl\\adl-bnn-textgen\\bnn\\Lib\\site-packages\\posteriors\\vi\\diag.py:171\u001b[39m, in \u001b[36mupdate\u001b[39m\u001b[34m(state, batch, log_posterior, optimizer, temperature, n_samples, stl, inplace)\u001b[39m\n\u001b[32m    161\u001b[39m     nelbo_grads, (nelbo_val, aux) = grad_and_value(\n\u001b[32m    162\u001b[39m         nelbo_log_sd, argnums=(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m), has_aux=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    163\u001b[39m     )(state.params, state.log_sd_diag)\n\u001b[32m    165\u001b[39m updates, opt_state = optimizer.update(\n\u001b[32m    166\u001b[39m     nelbo_grads,\n\u001b[32m    167\u001b[39m     state.opt_state,\n\u001b[32m    168\u001b[39m     params=[state.params, state.log_sd_diag],\n\u001b[32m    169\u001b[39m     inplace=inplace,\n\u001b[32m    170\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m mean, log_sd_diag = \u001b[43mtorchopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_updates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_sd_diag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m    176\u001b[39m     tree_insert_(state.nelbo, nelbo_val.detach())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayk_\\OneDrive\\Desktop\\05_LMU_Masters\\04_applied_dl\\adl-bnn-textgen\\bnn\\Lib\\site-packages\\torchopt\\update.py:76\u001b[39m, in \u001b[36mapply_updates\u001b[39m\u001b[34m(params, updates, inplace)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(p: torch.Tensor, u: torch.Tensor | \u001b[38;5;28;01mNone\u001b[39;00m) -> torch.Tensor:\n\u001b[32m     74\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m p.add(u) \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayk_\\OneDrive\\Desktop\\05_LMU_Masters\\04_applied_dl\\adl-bnn-textgen\\bnn\\Lib\\site-packages\\optree\\ops.py:766\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[39m\n\u001b[32m    764\u001b[39m leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[32m    765\u001b[39m flat_args = [leaves] + [treespec.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayk_\\OneDrive\\Desktop\\05_LMU_Masters\\04_applied_dl\\adl-bnn-textgen\\bnn\\Lib\\site-packages\\torchopt\\update.py:74\u001b[39m, in \u001b[36mapply_updates.<locals>.f\u001b[39m\u001b[34m(p, u)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(p: torch.Tensor, u: torch.Tensor | \u001b[38;5;28;01mNone\u001b[39;00m) -> torch.Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "state_vi, metrics_vi, eval_vi = run_bayesian_pipeline(training_batches, \n",
    "                                                      'vi',\n",
    "                                                      use_wandb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52af7d",
   "metadata": {},
   "source": [
    "#### Run Bayesian Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3e9ca",
   "metadata": {},
   "source": [
    "#### 8. Compare Deterministic vs Bayesian Predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
