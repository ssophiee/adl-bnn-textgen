{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4982daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 01:12:36.424000 23648 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\hayk_\\OneDrive\\Desktop\\05_LMU_Masters\\04_applied_dl\\adl-bnn-textgen\\bnn\\Lib\\site-packages\\posteriors\\utils.py:9: FutureWarning: The 'optree.integration' module is deprecated and will be removed in version 0.18.0. Please use 'optree.integrations' instead.\n",
      "  from optree.integration.torch import tree_ravel\n",
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.35MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 210kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.16MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.51MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn, utils, func\n",
    "import torchopt\n",
    "import posteriors\n",
    "\n",
    "dataset = MNIST(root=\"./data\", transform=ToTensor(), download=True)\n",
    "train_loader = utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "num_data = len(dataset)\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 10))\n",
    "params = dict(classifier.named_parameters())\n",
    "\n",
    "\n",
    "def log_posterior(params, batch):\n",
    "    images, labels = batch\n",
    "    images = images.view(images.size(0), -1)\n",
    "    output = func.functional_call(classifier, params, images)\n",
    "    log_post_val = (\n",
    "        -nn.functional.cross_entropy(output, labels)\n",
    "        + posteriors.diag_normal_log_prob(params) / num_data\n",
    "    )\n",
    "    return log_post_val, output\n",
    "\n",
    "\n",
    "transform = posteriors.vi.diag.build(\n",
    "    log_posterior, torchopt.adam(), temperature=1 / num_data\n",
    ")  # Can swap out for any posteriors algorithm\n",
    "\n",
    "state = transform.init(params)\n",
    "\n",
    "for batch in train_loader:\n",
    "    state, aux = transform.update(state, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6c8491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VIDiagState(\n",
       "    log_sd_diag=NonTensorData(data={'0.weight': tensor(  ...  _fn=<AddBackward0>)}, batch_size=torch.Size([]), device=None),\n",
       "    nelbo=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "    opt_state=NonTensorData(data=(ScaleByAdamState(mu  ...  75)]), EmptyState()), batch_size=torch.Size([]), device=None),\n",
       "    params=NonTensorData(data={'0.weight': tensor(  ...  _fn=<AddBackward0>)}, batch_size=torch.Size([]), device=None),\n",
       "    step=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7751702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.weight': Parameter containing:\n",
       " tensor([[-0.0052,  0.0240,  0.0209,  ...,  0.0121,  0.0262, -0.0279],\n",
       "         [-0.0175,  0.0174, -0.0278,  ...,  0.0083,  0.0111,  0.0032],\n",
       "         [-0.0202,  0.0014, -0.0341,  ...,  0.0337,  0.0331, -0.0287],\n",
       "         ...,\n",
       "         [-0.0056, -0.0087, -0.0113,  ...,  0.0127,  0.0035, -0.0339],\n",
       "         [-0.0041,  0.0234, -0.0162,  ..., -0.0269,  0.0226, -0.0132],\n",
       "         [-0.0045, -0.0061,  0.0332,  ...,  0.0236, -0.0133,  0.0164]],\n",
       "        requires_grad=True),\n",
       " '0.bias': Parameter containing:\n",
       " tensor([ 0.0225,  0.0145, -0.0231,  0.0010,  0.0088, -0.0040,  0.0124,  0.0150,\n",
       "         -0.0170,  0.0101, -0.0312,  0.0069,  0.0251,  0.0317,  0.0264, -0.0161,\n",
       "         -0.0174,  0.0206, -0.0267, -0.0046,  0.0246, -0.0042, -0.0082,  0.0013,\n",
       "          0.0116, -0.0339, -0.0340, -0.0124,  0.0152, -0.0239,  0.0214,  0.0008,\n",
       "          0.0182, -0.0315,  0.0104,  0.0230, -0.0215, -0.0023,  0.0154,  0.0176,\n",
       "          0.0330,  0.0032,  0.0150,  0.0003, -0.0224, -0.0072, -0.0017, -0.0042,\n",
       "         -0.0306, -0.0066,  0.0148,  0.0198, -0.0112, -0.0210, -0.0117,  0.0003,\n",
       "          0.0178, -0.0239,  0.0273,  0.0158,  0.0027,  0.0132,  0.0083, -0.0352],\n",
       "        requires_grad=True),\n",
       " '2.weight': Parameter containing:\n",
       " tensor([[ 7.8843e-02,  5.7354e-02, -4.3258e-02,  1.1581e-01, -1.2088e-01,\n",
       "           7.1192e-02, -1.1590e-01,  1.1787e-01, -7.9410e-02,  6.8872e-02,\n",
       "          -1.1365e-01, -6.2067e-02,  5.9041e-02,  1.0863e-01,  1.2394e-01,\n",
       "          -4.7104e-02,  7.5339e-02,  9.2091e-03,  1.0449e-01, -3.0181e-02,\n",
       "          -2.2630e-03,  4.5127e-02, -1.1203e-02, -1.1626e-01,  9.8571e-02,\n",
       "           5.8759e-02, -6.1189e-02, -1.9890e-02,  2.4205e-02, -1.8855e-02,\n",
       "          -3.3723e-02, -1.1277e-01,  3.1862e-02,  4.8169e-02, -1.0787e-01,\n",
       "          -1.1523e-01,  7.1340e-03, -3.1895e-02,  2.6123e-02,  6.5891e-02,\n",
       "           7.5826e-02,  3.2860e-03, -6.9572e-02, -9.6674e-02, -7.4099e-03,\n",
       "           1.1096e-01,  1.2459e-01,  1.6317e-02,  4.8400e-02,  5.7078e-02,\n",
       "          -1.1034e-01,  2.0223e-02, -7.5793e-02, -9.7289e-02,  1.2181e-01,\n",
       "          -2.6745e-02,  5.6000e-02, -8.9908e-02, -3.6711e-02,  7.5649e-02,\n",
       "           7.9033e-02,  5.7308e-02, -2.2950e-02, -1.0880e-01],\n",
       "         [ 4.2373e-02, -1.1186e-01, -1.1807e-01, -8.4122e-02, -7.0261e-02,\n",
       "          -2.2333e-03, -5.4285e-02,  8.2230e-02, -2.1152e-02,  5.1455e-04,\n",
       "          -2.6995e-02,  9.6256e-02,  2.9208e-02, -7.3656e-02, -4.2304e-02,\n",
       "           1.2068e-01, -4.8156e-02, -6.2645e-03, -3.4095e-02,  1.1916e-01,\n",
       "           7.4199e-02,  2.7678e-02,  1.5786e-02, -7.8560e-02,  8.2839e-02,\n",
       "           7.4800e-03, -9.3052e-02, -1.1125e-01,  5.8819e-02,  7.1617e-02,\n",
       "          -1.2199e-01,  4.5420e-02,  1.0435e-01, -7.9013e-02, -5.2028e-02,\n",
       "          -4.8760e-02,  9.6822e-02,  4.1751e-02,  5.1283e-03,  3.5646e-02,\n",
       "           9.3465e-02,  5.5020e-02,  1.2990e-02, -7.5294e-02, -4.1886e-02,\n",
       "          -2.4806e-02, -1.4474e-02, -3.2904e-02, -5.0955e-02, -6.0212e-02,\n",
       "           9.8561e-02,  8.0047e-02,  2.5568e-02, -1.5654e-03,  1.5416e-02,\n",
       "           1.1215e-01, -3.1428e-02, -1.6512e-02, -1.0791e-01,  4.1828e-02,\n",
       "          -5.3946e-02,  9.9627e-03,  9.4807e-02,  8.2760e-02],\n",
       "         [-4.7264e-02,  4.9480e-02,  4.8015e-02, -4.9796e-02, -1.1660e-01,\n",
       "          -9.3144e-02,  1.0942e-01, -1.0692e-01,  5.0181e-02,  1.0297e-01,\n",
       "          -9.0907e-02,  1.1203e-01, -1.1525e-01,  8.7236e-02, -1.8269e-02,\n",
       "          -9.5723e-02,  3.7165e-02,  9.7201e-02, -9.4364e-02, -6.4716e-04,\n",
       "          -7.6506e-02, -5.9673e-02,  6.8656e-04,  7.3877e-02,  3.2838e-02,\n",
       "          -3.3245e-02,  8.7491e-02, -1.1933e-02,  9.7277e-02,  1.1499e-01,\n",
       "          -8.0866e-02, -4.5833e-02,  5.3619e-02, -7.6172e-02,  1.0885e-01,\n",
       "          -3.4095e-02, -5.9203e-02,  7.5091e-02, -9.2427e-02, -8.8237e-02,\n",
       "           3.4272e-02, -2.3892e-02,  4.5420e-02,  3.1091e-02, -5.0606e-02,\n",
       "          -1.0265e-01,  7.5899e-02, -1.9961e-02, -3.8806e-02,  2.1569e-02,\n",
       "          -8.9563e-04, -4.9175e-02,  1.8004e-02, -3.6336e-02,  1.9472e-02,\n",
       "           7.1560e-02, -1.1703e-01, -1.7434e-02, -9.3819e-02,  8.4709e-02,\n",
       "           3.3666e-02,  9.2692e-02, -6.0285e-02,  7.8301e-02],\n",
       "         [ 1.2363e-01, -8.0795e-02, -9.3867e-02,  1.1328e-01, -4.6610e-02,\n",
       "          -7.0753e-02, -6.0088e-02, -1.0350e-01, -1.0457e-01, -4.6303e-02,\n",
       "           6.0624e-03, -2.3942e-02,  1.0873e-01,  1.2067e-01,  2.7356e-02,\n",
       "          -1.2237e-01, -1.1832e-01,  1.0995e-02, -7.3510e-04, -1.2085e-01,\n",
       "           5.2331e-03, -3.6121e-02, -4.7828e-02,  5.4266e-02, -6.3671e-02,\n",
       "           1.4832e-02,  9.1408e-02,  1.0024e-01, -5.1138e-02,  7.4841e-02,\n",
       "           3.3311e-02,  1.1935e-01, -1.5625e-02, -7.3487e-02, -9.2337e-02,\n",
       "           5.7859e-02,  7.1399e-03, -1.8013e-02, -9.1239e-02,  6.1657e-02,\n",
       "          -6.3401e-02,  3.7137e-02, -1.2410e-01,  1.1216e-01,  3.8983e-02,\n",
       "          -1.1360e-03,  2.1238e-03,  5.4580e-02,  8.5694e-02,  4.0135e-02,\n",
       "          -3.3142e-02,  1.2314e-01,  1.1317e-01,  1.1832e-01, -3.0991e-02,\n",
       "           5.4937e-02,  9.7594e-02, -4.6646e-03,  7.7062e-02, -8.2160e-02,\n",
       "           6.4910e-03,  5.6374e-03,  3.4422e-02, -2.9255e-02],\n",
       "         [-7.9115e-02,  3.0306e-02,  9.0508e-02, -1.0074e-01,  5.4349e-03,\n",
       "           5.6497e-02,  4.7740e-02,  5.7273e-02, -9.8785e-02, -1.1794e-01,\n",
       "           9.8992e-02,  1.1139e-01, -2.9014e-02,  5.3667e-02, -7.0146e-02,\n",
       "          -9.9425e-02,  2.2206e-02, -1.1396e-01,  5.2053e-02,  1.0528e-02,\n",
       "          -1.1407e-01,  6.5614e-02,  1.1862e-01,  4.9241e-02,  7.7569e-02,\n",
       "           9.4319e-02,  1.1134e-01, -9.3128e-02, -8.8360e-02,  1.1047e-02,\n",
       "           3.2939e-02,  7.5884e-02, -8.1540e-02, -7.1907e-02, -1.1396e-01,\n",
       "           6.5744e-02,  3.8627e-02, -7.7945e-02, -1.0757e-01,  5.6423e-02,\n",
       "          -8.1336e-02,  1.4707e-03,  1.7457e-02, -3.9766e-02,  1.2355e-01,\n",
       "           1.0699e-01,  9.3465e-02,  4.1694e-02, -1.2447e-02,  7.5773e-02,\n",
       "          -1.1884e-01, -9.5547e-02, -7.7740e-02,  9.9740e-03,  1.1396e-01,\n",
       "           3.0089e-02,  3.6322e-02, -1.1375e-01,  1.6772e-02, -2.9540e-02,\n",
       "           5.9149e-02,  7.9958e-02, -3.2773e-02,  4.6107e-02],\n",
       "         [ 9.6819e-03,  2.3155e-02,  9.4608e-02,  9.7223e-03, -3.9782e-02,\n",
       "           7.4342e-02, -4.6228e-02, -5.7129e-03, -9.9599e-02, -1.0451e-01,\n",
       "           1.6365e-02, -5.4083e-02, -7.8391e-02, -7.0625e-02, -7.1052e-02,\n",
       "           1.1364e-01,  5.9578e-02, -4.3810e-02, -1.0174e-01,  3.3885e-02,\n",
       "           6.9829e-02,  3.0740e-02,  7.0936e-02, -4.8461e-03, -6.7381e-02,\n",
       "           1.0882e-01, -5.4828e-02, -2.9301e-03, -8.0898e-02,  1.0944e-02,\n",
       "          -9.8772e-02,  1.0433e-01,  1.0736e-01, -7.2497e-02,  1.1767e-02,\n",
       "          -9.5769e-02, -4.7913e-02, -6.8275e-02, -1.1390e-01, -9.1324e-02,\n",
       "           1.5772e-02,  1.0961e-01, -6.3926e-02, -1.0495e-01,  1.0919e-01,\n",
       "           1.6420e-02, -7.1727e-02,  1.2007e-01,  8.2169e-02, -6.6974e-02,\n",
       "           6.6463e-02,  9.3425e-02, -1.1929e-01, -1.0249e-01, -2.5801e-02,\n",
       "           7.0347e-02, -7.4519e-02,  7.0387e-02,  7.7111e-02,  1.1770e-01,\n",
       "          -2.8023e-03,  1.0985e-01, -4.1907e-02,  1.0169e-01],\n",
       "         [-1.0335e-01,  9.8031e-02,  4.4704e-02, -7.2030e-02,  1.3637e-02,\n",
       "          -1.2318e-03,  1.1975e-01, -3.6373e-02,  8.7626e-02,  6.4383e-02,\n",
       "           3.6874e-03,  6.5332e-02, -5.4739e-02, -2.7926e-02, -9.7672e-02,\n",
       "           3.8681e-02,  4.9885e-03,  7.7402e-03,  3.4332e-02,  7.7540e-02,\n",
       "          -8.8890e-02,  5.8273e-03,  1.3030e-03,  1.3169e-02, -1.1959e-01,\n",
       "          -1.2465e-01, -8.5978e-02,  8.7936e-02,  1.1219e-01, -3.1990e-02,\n",
       "          -7.7696e-02,  9.1440e-02,  1.0761e-01,  1.1621e-01,  7.1995e-02,\n",
       "           4.3998e-02,  4.1279e-02, -6.4542e-02, -1.0414e-01,  6.9067e-02,\n",
       "           3.8318e-02, -9.0285e-02, -6.2972e-03,  8.7414e-03, -1.5143e-02,\n",
       "          -1.1654e-01,  6.6127e-02,  2.1879e-02, -7.0581e-02, -9.1521e-04,\n",
       "          -8.3137e-02, -1.1839e-01, -9.1382e-02,  5.0605e-02, -1.8946e-02,\n",
       "          -1.2118e-04,  1.3645e-02, -9.2083e-02, -1.7131e-02, -4.8827e-03,\n",
       "          -1.1489e-01,  1.1876e-01, -4.8344e-02,  3.9548e-02],\n",
       "         [-5.2518e-02,  5.5373e-02, -2.9149e-02, -3.2122e-02, -7.1500e-02,\n",
       "           1.2102e-01,  7.0262e-02,  3.0486e-02,  6.1909e-02, -8.5887e-02,\n",
       "           1.0816e-01, -1.2375e-01, -1.1491e-01, -1.1009e-01, -7.4852e-02,\n",
       "          -1.1116e-01,  1.0836e-01,  2.8279e-02,  4.0574e-02,  1.3063e-02,\n",
       "           6.3534e-02, -6.6614e-02,  1.3560e-02, -3.5884e-02,  6.2676e-02,\n",
       "          -7.1538e-02,  5.4982e-02,  8.1084e-02,  6.9220e-02,  3.0172e-02,\n",
       "          -6.6602e-02, -1.4621e-02, -8.3804e-02,  6.1244e-02, -1.0171e-01,\n",
       "           1.1605e-01, -5.3530e-02, -9.6994e-02, -3.3673e-02,  6.5385e-02,\n",
       "           8.0423e-02, -1.2229e-01, -1.2371e-01, -7.1716e-02, -1.0332e-01,\n",
       "           7.4862e-02, -6.2291e-03,  7.8496e-02, -1.1676e-01,  5.6317e-02,\n",
       "           8.6165e-02, -5.5412e-02, -3.1823e-02, -1.0278e-01, -1.0963e-01,\n",
       "           1.3119e-04,  1.0076e-02, -1.2192e-01,  7.8826e-02,  4.1952e-03,\n",
       "           2.9232e-02,  9.0273e-02,  6.2752e-02, -6.6811e-02],\n",
       "         [-1.4103e-02, -7.3777e-02, -8.5244e-02,  1.1390e-02,  8.1692e-02,\n",
       "           1.3628e-03, -3.8527e-02, -5.2386e-02,  9.5017e-02, -5.3507e-02,\n",
       "          -3.0110e-02,  3.7586e-02,  5.5729e-03, -6.5399e-02,  1.1644e-01,\n",
       "           1.0909e-01, -2.8551e-02, -5.4506e-02,  4.9538e-02, -4.3763e-02,\n",
       "           5.7978e-02, -7.3958e-02, -1.3856e-02, -8.4422e-02,  4.9593e-02,\n",
       "          -6.4153e-02, -4.8564e-02,  5.1857e-02, -8.4825e-02,  2.5238e-02,\n",
       "          -9.8666e-02, -8.2078e-02,  2.5291e-02,  5.8273e-02,  1.2218e-01,\n",
       "          -1.2325e-01,  9.5614e-02,  9.4951e-02,  4.9600e-02,  7.7250e-03,\n",
       "          -4.7808e-02, -8.4798e-02,  5.5348e-02, -1.9694e-03,  2.4926e-02,\n",
       "          -9.9632e-02, -3.0400e-02, -3.4055e-02,  8.8146e-02, -6.0897e-02,\n",
       "           2.0177e-03, -6.5408e-02,  4.7814e-03,  1.0820e-01, -2.0524e-02,\n",
       "          -1.9789e-02,  3.1361e-02, -6.7700e-02, -9.0766e-02,  5.9575e-02,\n",
       "          -4.7428e-02,  1.1254e-01,  1.0328e-01, -1.9527e-02],\n",
       "         [-8.3152e-02, -3.6594e-02,  1.4945e-03,  2.0099e-04, -2.3940e-02,\n",
       "           8.3834e-02, -5.9753e-02,  1.3058e-02, -2.5742e-02,  2.9646e-02,\n",
       "           6.5692e-02, -5.6887e-02,  9.2989e-03,  1.1318e-01,  1.8196e-02,\n",
       "           1.1366e-01, -4.7941e-02,  2.3783e-02,  1.1059e-01,  6.7056e-02,\n",
       "           2.7776e-02, -1.2698e-02,  2.8943e-02,  2.6758e-02, -1.2009e-01,\n",
       "          -3.9205e-02,  3.2889e-02, -9.5483e-02,  3.1519e-02, -7.6279e-04,\n",
       "           8.0892e-02, -4.7441e-02, -1.0619e-01, -4.6579e-03,  8.1632e-02,\n",
       "           1.1624e-01,  4.4797e-02,  8.7326e-02, -2.5484e-02,  8.1081e-03,\n",
       "          -8.1623e-03, -1.8489e-04,  3.8576e-02,  1.0457e-01,  3.0238e-02,\n",
       "          -3.6996e-02, -8.0627e-02,  4.9719e-02,  6.6200e-02, -7.7144e-02,\n",
       "          -5.2694e-02,  4.0539e-02,  5.5575e-02,  2.4588e-02, -3.7439e-03,\n",
       "           1.1995e-01, -1.0996e-01,  1.0326e-01,  1.1569e-01, -9.8345e-02,\n",
       "          -7.8426e-02,  6.3725e-02, -2.8616e-02,  6.6800e-02]],\n",
       "        requires_grad=True),\n",
       " '2.bias': Parameter containing:\n",
       " tensor([-0.0863,  0.0244, -0.0491,  0.0926, -0.0668,  0.1139,  0.0127,  0.0598,\n",
       "         -0.0560,  0.0337], requires_grad=True)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e4256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.weight': tensor([[ 1.2148e-11,  4.4999e-11,  2.4448e-12,  ..., -5.6119e-11,\n",
       "          -3.6033e-11,  5.6699e-12],\n",
       "         [ 2.7890e-11, -2.8715e-12, -1.1627e-11,  ..., -7.4761e-14,\n",
       "          -3.8051e-11,  1.3771e-05],\n",
       "         [ 7.3005e-11, -1.2755e-10,  1.4253e-12,  ..., -2.6487e-11,\n",
       "           1.0827e-11, -5.9081e-11],\n",
       "         ...,\n",
       "         [-7.1553e-10, -1.7301e-05, -2.5226e-11,  ..., -1.7831e-12,\n",
       "           1.6229e-06, -7.3980e-11],\n",
       "         [ 2.4941e-04,  2.6498e-11, -1.3135e-12,  ..., -1.0180e-10,\n",
       "          -1.0406e-11, -1.2345e-10],\n",
       "         [-1.2255e-09, -5.8497e-08, -2.2756e-11,  ...,  3.8858e-11,\n",
       "          -8.6702e-12, -6.2145e-12]], grad_fn=<AddBackward0>),\n",
       " '0.bias': tensor([-0.2730, -0.2983, -0.3322, -0.3118, -0.3095, -0.3152, -0.2916, -0.2834,\n",
       "         -0.3261, -0.3092, -0.3483, -0.2879, -0.2817, -0.2944, -0.2982, -0.3312,\n",
       "         -0.3203, -0.2900, -0.3435, -0.3187, -0.2641, -0.2929, -0.3270, -0.2912,\n",
       "         -0.2935, -0.3539, -0.3218, -0.3300, -0.2803, -0.3293, -0.2810, -0.2917,\n",
       "         -0.2692, -0.3232, -0.3032, -0.2757, -0.3329, -0.3065, -0.2842, -0.2895,\n",
       "         -0.2734, -0.3031, -0.2768, -0.3094, -0.3299, -0.3134, -0.3006, -0.3061,\n",
       "         -0.3517, -0.3265, -0.2838, -0.2529, -0.3213, -0.3378, -0.3085, -0.2855,\n",
       "         -0.3008, -0.3210, -0.2557, -0.3008, -0.3030, -0.3046, -0.2953, -0.3413],\n",
       "        grad_fn=<AddBackward0>),\n",
       " '2.weight': tensor([[ 0.0919,  0.0585, -0.0499,  0.0853, -0.1279,  0.0596, -0.1049,  0.1116,\n",
       "          -0.0617,  0.0419, -0.0733, -0.0394,  0.0504,  0.1110,  0.1185, -0.0494,\n",
       "           0.0696, -0.0044,  0.1021, -0.0545, -0.0268,  0.0219, -0.0174, -0.0951,\n",
       "           0.0964,  0.0545, -0.0891, -0.0188,  0.0003, -0.0166, -0.0350, -0.1097,\n",
       "           0.0314,  0.0325, -0.1125, -0.1166, -0.0142, -0.0345,  0.0429,  0.0658,\n",
       "           0.0577, -0.0212, -0.0684, -0.0986, -0.0067,  0.0812,  0.1432,  0.0132,\n",
       "           0.0495,  0.0496, -0.1344, -0.0105, -0.0731, -0.0803,  0.1030, -0.0510,\n",
       "           0.0576, -0.0870, -0.0368,  0.0401,  0.0825,  0.0780, -0.0264, -0.1111],\n",
       "         [ 0.0686, -0.0865, -0.0452, -0.0382, -0.0467,  0.0163,  0.0070,  0.1626,\n",
       "           0.0258,  0.0335, -0.0135,  0.1052,  0.0818, -0.0624,  0.0055,  0.1307,\n",
       "          -0.0244,  0.0626,  0.0277,  0.1920,  0.0556,  0.0644,  0.0564, -0.0394,\n",
       "           0.0661,  0.0347, -0.0553, -0.0590,  0.1172,  0.0878, -0.0866,  0.0735,\n",
       "           0.1416, -0.0696,  0.0131,  0.0056,  0.1223,  0.0968,  0.0467,  0.0832,\n",
       "           0.1240,  0.1058,  0.0610, -0.0234,  0.0153,  0.0175,  0.0427,  0.0063,\n",
       "           0.0003, -0.0325,  0.1617,  0.1354,  0.1066,  0.0571,  0.0721,  0.1803,\n",
       "          -0.0061,  0.0077, -0.0578,  0.0659, -0.0119,  0.0676,  0.1255,  0.1467],\n",
       "         [-0.0242,  0.0409,  0.0456, -0.0242, -0.1220, -0.0714,  0.0980, -0.1122,\n",
       "           0.0634,  0.0831, -0.1023,  0.1174, -0.0857,  0.1006, -0.0263, -0.1005,\n",
       "           0.0539,  0.0922, -0.0675, -0.0071, -0.0709, -0.0715,  0.0133,  0.0590,\n",
       "           0.0367, -0.0425,  0.0712, -0.0127,  0.0746,  0.1225, -0.0989, -0.0410,\n",
       "           0.0786, -0.0680,  0.0886, -0.0317, -0.0340,  0.0690, -0.0665, -0.0970,\n",
       "           0.0427,  0.0080,  0.0846,  0.0411, -0.0688, -0.1074,  0.0551, -0.0484,\n",
       "          -0.0372,  0.0104,  0.0159, -0.0584, -0.0033, -0.0226,  0.0152,  0.0899,\n",
       "          -0.0883, -0.0073, -0.0959,  0.0943,  0.0326,  0.0987, -0.0490,  0.0809],\n",
       "         [ 0.1267, -0.0575, -0.1138,  0.0862, -0.0420, -0.0749, -0.0554, -0.0878,\n",
       "          -0.1067, -0.0422,  0.0084, -0.0211,  0.0959,  0.1123, -0.0052, -0.1170,\n",
       "          -0.1346,  0.0300, -0.0020, -0.1205, -0.0011, -0.0431, -0.0622,  0.0704,\n",
       "          -0.0539,  0.0095,  0.0477,  0.0801, -0.0343,  0.0489,  0.0432,  0.1048,\n",
       "          -0.0367, -0.0578, -0.0920,  0.0345, -0.0065, -0.0203, -0.1164,  0.0612,\n",
       "          -0.0598,  0.0313, -0.1092,  0.0982,  0.0208, -0.0034,  0.0245,  0.0634,\n",
       "           0.0701,  0.0719, -0.0429,  0.0939,  0.1000,  0.0802, -0.0229,  0.0435,\n",
       "           0.0737,  0.0147,  0.0898, -0.0796,  0.0165,  0.0282,  0.0404, -0.0061],\n",
       "         [-0.0899,  0.0362,  0.1157, -0.0976,  0.0257,  0.0565,  0.0351,  0.0588,\n",
       "          -0.0893, -0.0962,  0.1181,  0.1216, -0.0192,  0.0490, -0.0856, -0.0683,\n",
       "           0.0683, -0.1284,  0.0423,  0.0225, -0.0879,  0.0512,  0.1112,  0.0149,\n",
       "           0.0773,  0.1076,  0.1124, -0.1039, -0.0889,  0.0005,  0.0421,  0.1030,\n",
       "          -0.0970, -0.0474, -0.1072,  0.0663,  0.0340, -0.0829, -0.0877,  0.0453,\n",
       "          -0.0969,  0.0012,  0.0102, -0.0379,  0.1111,  0.1087,  0.1022,  0.0413,\n",
       "          -0.0020,  0.0476, -0.1107, -0.0382, -0.0648, -0.0021,  0.1161,  0.0265,\n",
       "           0.0441, -0.1146,  0.0040, -0.0279,  0.0439,  0.0688, -0.0144,  0.0283],\n",
       "         [ 0.0034,  0.0087,  0.0579, -0.0095, -0.0523,  0.0624, -0.0656, -0.0380,\n",
       "          -0.1056, -0.1012, -0.0322, -0.0840, -0.0672, -0.0783, -0.0321,  0.1205,\n",
       "           0.0480, -0.0265, -0.1121,  0.0318,  0.0520,  0.0347,  0.0635,  0.0177,\n",
       "          -0.0645,  0.0873, -0.0624, -0.0257, -0.0674, -0.0049, -0.0979,  0.0832,\n",
       "           0.1024, -0.0587, -0.0036, -0.1118, -0.0446, -0.0825, -0.1269, -0.0837,\n",
       "           0.0387,  0.0715, -0.0737, -0.1140,  0.0718, -0.0012, -0.0726,  0.1153,\n",
       "           0.0572, -0.0699,  0.0167,  0.0752, -0.1134, -0.1155, -0.0307,  0.0591,\n",
       "          -0.0577,  0.0326,  0.0610,  0.1032, -0.0264,  0.0844, -0.0336,  0.1077],\n",
       "         [-0.1130,  0.0810,  0.0372, -0.0202,  0.0019, -0.0079,  0.0790, -0.0597,\n",
       "           0.0784,  0.0655, -0.0220,  0.0813, -0.0634, -0.0013, -0.1064,  0.0286,\n",
       "           0.0100,  0.0033,  0.0486,  0.0853, -0.0812, -0.0041,  0.0185, -0.0043,\n",
       "          -0.1089, -0.1528, -0.0563,  0.0859,  0.1166, -0.0071, -0.0783,  0.0935,\n",
       "           0.1312,  0.1128,  0.0725,  0.0648,  0.0618, -0.0479, -0.0928,  0.0535,\n",
       "           0.0170, -0.0878, -0.0316,  0.0170,  0.0148, -0.0969,  0.0455,  0.0135,\n",
       "          -0.0690,  0.0334, -0.0535, -0.1216, -0.0904,  0.0565, -0.0331,  0.0116,\n",
       "           0.0249, -0.1007, -0.0217, -0.0090, -0.1034,  0.1050, -0.0395,  0.0349],\n",
       "         [-0.0298,  0.1105,  0.0061, -0.0125, -0.0331,  0.1554,  0.1076,  0.0465,\n",
       "           0.0688, -0.0562,  0.1519, -0.0593, -0.0744, -0.0856, -0.0288, -0.0714,\n",
       "           0.1235,  0.0298,  0.0480,  0.0345,  0.1231,  0.0040,  0.0436, -0.0312,\n",
       "           0.0889, -0.0364,  0.1138,  0.1164,  0.0761,  0.0928, -0.0181, -0.0252,\n",
       "          -0.0229,  0.0753, -0.0616,  0.1335, -0.0145, -0.0635, -0.0007,  0.0862,\n",
       "           0.0809, -0.1166, -0.1012, -0.0275, -0.0706,  0.1099,  0.0224,  0.0910,\n",
       "          -0.0693,  0.0827,  0.1224, -0.0223, -0.0027, -0.0462, -0.0534,  0.0343,\n",
       "           0.0142, -0.0632,  0.1052,  0.0323,  0.1015,  0.1378,  0.0505, -0.0405],\n",
       "         [-0.0226, -0.0805, -0.0917, -0.0045,  0.0530, -0.0075, -0.0445, -0.0691,\n",
       "           0.0591, -0.0698, -0.0405, -0.0045, -0.0324, -0.0707,  0.0943,  0.0904,\n",
       "          -0.0550, -0.0637,  0.0243, -0.0780,  0.0564, -0.0833, -0.0229, -0.0882,\n",
       "           0.0275, -0.0583, -0.0595,  0.0387, -0.0888, -0.0026, -0.1125, -0.0854,\n",
       "          -0.0094,  0.0300,  0.0920, -0.1300,  0.0544,  0.0761,  0.0391, -0.0132,\n",
       "          -0.0483, -0.0868,  0.0192, -0.0353,  0.0057, -0.1181, -0.0542, -0.0410,\n",
       "           0.0459, -0.0467, -0.0152, -0.0689, -0.0135,  0.0746, -0.0384, -0.0618,\n",
       "           0.0064, -0.1055, -0.0846,  0.0500, -0.0713,  0.0633,  0.0664, -0.0522],\n",
       "         [-0.1010, -0.0558,  0.0080, -0.0078,  0.0015,  0.0832, -0.0591,  0.0184,\n",
       "          -0.0236,  0.0235,  0.0732, -0.0877, -0.0108,  0.1014,  0.0371,  0.0929,\n",
       "          -0.0476,  0.0164,  0.0671,  0.0566,  0.0178, -0.0095,  0.0209,  0.0383,\n",
       "          -0.0988, -0.0317,  0.0455, -0.0872,  0.0349,  0.0043,  0.0608, -0.0263,\n",
       "          -0.1084,  0.0065,  0.0618,  0.0986,  0.0296,  0.0813, -0.0506,  0.0289,\n",
       "           0.0211, -0.0175,  0.0425,  0.0967,  0.0485, -0.0298, -0.1145,  0.0742,\n",
       "           0.0852, -0.0833, -0.0615,  0.0633,  0.0236,  0.0269, -0.0229,  0.1090,\n",
       "          -0.1067,  0.1110,  0.1006, -0.0677, -0.0948,  0.0683, -0.0335,  0.0416]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " '2.bias': tensor([-0.0661,  0.1199, -0.0859,  0.0997, -0.0447, -0.0072, -0.0184,  0.0991,\n",
       "          0.0080,  0.0145], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327cfd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c068b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss (state.params): 2.3025\n",
      "Average Loss (original params): 2.3074\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "classifier.eval()\n",
    "total_loss_state = 0.0\n",
    "total_loss_original = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        images = images.view(images.size(0), -1)\n",
    "        \n",
    "        # Loss for state.params\n",
    "        output_state = func.functional_call(classifier, state.params, images)\n",
    "        loss_state = nn.functional.cross_entropy(output_state, labels)\n",
    "        total_loss_state += loss_state.item()\n",
    "        \n",
    "        # Loss for original params\n",
    "        output_original = func.functional_call(classifier, params, images)\n",
    "        loss_original = nn.functional.cross_entropy(output_original, labels)\n",
    "        total_loss_original += loss_original.item()\n",
    "        \n",
    "        num_batches += 1\n",
    "\n",
    "avg_loss_state = total_loss_state / num_batches\n",
    "avg_loss_original = total_loss_original / num_batches\n",
    "\n",
    "print(f\"Average Loss (state.params): {avg_loss_state:.4f}\")\n",
    "print(f\"Average Loss (original params): {avg_loss_original:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074de97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
