{
  "sampler_type": "vi",
  "config": {
    "batch_size": 32,
    "train_samples": 2000,
    "max_seq_length": 128,
    "num_epochs": 1,
    "learning_rate": 1e-05,
    "temperature": 0.01,
    "vi_n_samples": 1,
    "prior_std": 0.1,
    "prior_strength": 10.0,
    "init_log_scale": -10,
    "max_log_scale": -5,
    "num_samples": 10,
    "max_new_tokens": 100,
    "generation_temperature": 0.8,
    "save_dir": "checkpoints/samplers",
    "wandb_project": "bayesian-nanogpt",
    "weight_decay": 0.01,
    "kl_weight": 1.0
  },
  "training_metrics": {
    "training_losses": [
      1.261295619465056
    ],
    "log_posterior_values": [
      7432.4462968129965
    ],
    "epoch_times": [
      524.769944
    ],
    "sampler_specific_metrics": [
      {
        "epoch": 0
      }
    ]
  },
  "timestamp": "2025-10-14T18:18:23.174848",
  "evaluation": {
    "deterministic": {
      "loss": 0.5185390114784241,
      "perplexity": 1.6795719861984253
    },
    "posterior_mean": {
      "loss": 0.5187925696372986,
      "perplexity": 1.6799979209899902,
      "improvement_over_deterministic": -0.0002535581588745117,
      "better_than_deterministic": false
    },
    "posterior_sampling": {
      "mean_loss": 62.93364639282227,
      "std_loss": 5.752681107821174,
      "min_loss": 53.69442367553711,
      "max_loss": 71.4796142578125,
      "num_samples": 5
    },
    "uncertainty": {
      "avg_predictive_entropy": 1.6893161535263062,
      "max_predictive_entropy": 1.9636247158050537,
      "min_predictive_entropy": 1.4648804664611816
    }
  }
}