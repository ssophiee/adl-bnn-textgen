{
  "sampler_type": "vi",
  "config": {
    "batch_size": 16,
    "num_epochs": 1,
    "learning_rate": 5e-06,
    "max_new_tokens": 100,
    "generation_temperature": 0.8,
    "num_samples": 10,
    "max_seq_length": 128,
    "train_samples": 500,
    "save_dir": "checkpoints/samplers",
    "wandb_project": "bayesian-nanogpt",
    "temperature": 0.001,
    "vi_n_samples": 1,
    "prior_std": 0.01
  },
  "training_metrics": {
    "training_losses": [
      1.1638013999909163
    ],
    "log_posterior_values": [
      -91198.34912109375
    ],
    "epoch_times": [
      82.979107
    ],
    "sampler_specific_metrics": [
      {
        "epoch": 0
      }
    ]
  },
  "timestamp": "2025-10-14T16:59:12.382654",
  "evaluation": {
    "deterministic": {
      "loss": 0.5422568917274475,
      "perplexity": 1.7198840379714966
    },
    "posterior_mean": {
      "loss": 0.5421388149261475,
      "perplexity": 1.7196810245513916,
      "improvement_over_deterministic": 0.00011807680130004883,
      "better_than_deterministic": true
    },
    "posterior_sampling": {
      "mean_loss": 70.69390869140625,
      "std_loss": 4.848119805633901,
      "min_loss": 61.979888916015625,
      "max_loss": 75.36688995361328,
      "num_samples": 5
    },
    "uncertainty": {
      "avg_predictive_entropy": 1.6918113231658936,
      "max_predictive_entropy": 1.9768344163894653,
      "min_predictive_entropy": 1.6137233972549438
    }
  }
}