
======================================================================
BAYESIAN MODEL TRAINING SUMMARY
======================================================================
Sampler: VI
Generated: 2025-10-05T22:32:47.712384

CONFIGURATION:
----------------------------------------------------------------------
  batch_size: 12
  num_epochs: 3
  learning_rate: 1e-05
  max_new_tokens: 100
  generation_temperature: 0.8
  num_samples: 5
  max_seq_length: 128
  train_samples: 200
  save_dir: checkpoints/samplers/vi_sampler
  wandb_project: bayesian-nanogpt
  temperature: 0.005

TRAINING SUMMARY:
----------------------------------------------------------------------
Total Epochs: 3
Final Training Loss: 1.2368
Final Log Posterior: -49414.1960
Total Training Time: 410.38s
Avg Time per Epoch: 136.79s

EVALUATION RESULTS:
----------------------------------------------------------------------

Deterministic Model (Original):
  Loss: 0.4762
  Perplexity: 1.6099

Bayesian Posterior Mean:
  Loss: 0.4762
  Perplexity: 1.6100
  Improvement: -0.0000
  Status: ✗ Worse than deterministic

Posterior Sampling (5 samples):
  Mean Loss: 63.2228 ± 12.0751
  Loss Range: [53.0737, 86.5179]

Uncertainty Quantification:
  Avg Predictive Entropy: 1.7229
  Entropy Range: [1.4027, 2.1029]

======================================================================
