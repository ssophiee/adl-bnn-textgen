{
  "sampler_type": "vi",
  "config": {
    "batch_size": 16,
    "num_epochs": 3,
    "learning_rate": 5e-06,
    "max_new_tokens": 100,
    "generation_temperature": 0.8,
    "num_samples": 10,
    "max_seq_length": 128,
    "train_samples": 500,
    "save_dir": "checkpoints/samplers/vi_sampler",
    "wandb_project": "bayesian-nanogpt",
    "temperature": 0.001,
    "vi_n_samples": 1,
    "prior_std": 0.1
  },
  "training_metrics": {
    "training_losses": [
      1.2392488047480583,
      1.2162519861012697,
      1.2236988842487335
    ],
    "log_posterior_values": [
      -19766.39044189453,
      -19766.395446777344,
      -19766.408447265625
    ],
    "epoch_times": [
      245.043078,
      185.035102,
      237.771824
    ],
    "sampler_specific_metrics": [
      {
        "epoch": 0
      },
      {
        "epoch": 1
      },
      {
        "epoch": 2
      }
    ]
  },
  "timestamp": "2025-10-05T23:18:05.631454",
  "evaluation": {
    "deterministic": {
      "loss": 1.0171266794204712,
      "perplexity": 2.765237808227539
    },
    "posterior_mean": {
      "loss": 1.0172455310821533,
      "perplexity": 2.76556658744812,
      "improvement_over_deterministic": -0.0001188516616821289,
      "better_than_deterministic": false
    },
    "posterior_sampling": {
      "mean_loss": 67.86453628540039,
      "std_loss": 4.832474757572779,
      "min_loss": 60.07172775268555,
      "max_loss": 74.7810287475586,
      "num_samples": 5
    },
    "uncertainty": {
      "avg_predictive_entropy": 1.7029131650924683,
      "max_predictive_entropy": 1.8809289932250977,
      "min_predictive_entropy": 1.4255093336105347
    }
  }
}