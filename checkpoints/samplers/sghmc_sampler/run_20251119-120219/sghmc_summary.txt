
======================================================================
BAYESIAN MODEL TRAINING SUMMARY
======================================================================
Sampler: SGHMC
Generated: 2025-11-19T12:02:19.570269

CONFIGURATION:
----------------------------------------------------------------------
  batch_size: 16
  train_samples: 10000
  max_seq_length: 128
  num_epochs: 15
  learning_rate: 1e-05
  temperature: 1.0
  vi_n_samples: 1
  prior_std: 1
  prior_strength: 10.0
  init_log_scale: -5
  max_log_scale: 2
  prior_beta: 0.0001
  num_samples: 10
  max_new_tokens: 100
  generation_temperature: 0.8
  save_dir: checkpoints/samplers
  wandb_project: bayesian-nanogpt
  weight_decay: 0.01
  kl_weight: 1.0
  sghmc_alpha: 0.1
  sghmc_beta: 0.0
  sghmc_sigma: 1.0
  warmup_steps: 200
  sampling_steps: 1000
  thinning: 10

TRAINING SUMMARY:
----------------------------------------------------------------------
Total Steps: 1200
Samples Collected: 100
Avg Momentum: 0.798392

======================================================================
