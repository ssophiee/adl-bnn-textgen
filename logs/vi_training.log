2025-10-14 14:48:40 - root - INFO - ======================================================================
2025-10-14 14:48:40 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 14:48:40 - root - INFO - ======================================================================
2025-10-14 14:48:40 - root - INFO - Sampler: VI
2025-10-14 14:48:40 - root - INFO - Log file: logs/vi_training.log
2025-10-14 14:48:40 - root - INFO - Using W&B: True
2025-10-14 14:48:40 - root - INFO - ======================================================================
2025-10-14 14:48:40 - root - INFO - Random seed set to: 42
2025-10-14 14:48:40 - root - INFO - Overriding epochs: 8
2025-10-14 14:48:40 - root - INFO - 
======================================================================
2025-10-14 14:48:40 - root - INFO - Loading pre-trained model...
2025-10-14 14:48:40 - root - INFO - ======================================================================
2025-10-14 14:48:40 - root - INFO - Model loaded successfully!
2025-10-14 14:48:40 - root - INFO - Vocabulary size: 65
2025-10-14 14:48:40 - root - INFO - 
======================================================================
2025-10-14 14:48:40 - root - INFO - Preparing training data...
2025-10-14 14:48:40 - root - INFO - ======================================================================
2025-10-14 14:48:40 - root - INFO - Created 32 training batches
2025-10-14 14:48:40 - root - INFO - Batch shape: torch.Size([16, 128])
2025-10-14 14:48:40 - root - INFO - Target shape: torch.Size([16, 1])
2025-10-14 14:48:40 - root - INFO - Total training samples: 500
2025-10-14 14:48:40 - root - INFO - 
======================================================================
2025-10-14 14:48:40 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 14:48:40 - root - INFO - ======================================================================
2025-10-14 14:48:40 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 14:48:40 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 14:48:40 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 14:48:40 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 14:48:40 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 14:48:41 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 14:48:41 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 14:48:41 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 14:57:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 14:57:10 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 14:57:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 14:57:10 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 14:57:10 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 14:57:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 14:57:11 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 14:57:11 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 14:57:11 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 14:57:19 - root - INFO - 
======================================================================
2025-10-14 14:57:19 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-14 14:57:19 - root - INFO - ======================================================================
2025-10-14 14:57:19 - root - INFO - Final Training Loss: 1.1558
2025-10-14 14:57:19 - root - INFO - Final Log Posterior: -19766.3157
2025-10-14 14:57:19 - root - INFO - 
Evaluation Results:
2025-10-14 14:57:19 - root - INFO -   Deterministic Loss: 0.5423
2025-10-14 14:57:19 - root - INFO -   Bayesian Loss: 0.5421
2025-10-14 14:57:19 - root - INFO -   Improvement: +0.0001
2025-10-14 14:57:19 - root - INFO -   Better than deterministic: True
2025-10-14 14:57:19 - root - INFO - ======================================================================
2025-10-14 14:57:19 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-14 14:57:19 - root - INFO - ======================================================================
2025-10-14 15:13:01 - root - INFO - ======================================================================
2025-10-14 15:13:01 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 15:13:01 - root - INFO - ======================================================================
2025-10-14 15:13:01 - root - INFO - Sampler: VI
2025-10-14 15:13:01 - root - INFO - Log file: logs/vi_training.log
2025-10-14 15:13:01 - root - INFO - Using W&B: True
2025-10-14 15:13:01 - root - INFO - ======================================================================
2025-10-14 15:13:01 - root - INFO - Random seed set to: 42
2025-10-14 15:13:01 - root - INFO - 
======================================================================
2025-10-14 15:13:01 - root - INFO - Loading pre-trained model...
2025-10-14 15:13:01 - root - INFO - ======================================================================
2025-10-14 15:13:01 - root - INFO - Model loaded successfully!
2025-10-14 15:13:01 - root - INFO - Vocabulary size: 65
2025-10-14 15:13:01 - root - INFO - 
======================================================================
2025-10-14 15:13:01 - root - INFO - Preparing training data...
2025-10-14 15:13:01 - root - INFO - ======================================================================
2025-10-14 15:13:01 - root - INFO - Created 32 training batches
2025-10-14 15:13:01 - root - INFO - Batch shape: torch.Size([16, 128])
2025-10-14 15:13:01 - root - INFO - Target shape: torch.Size([16, 1])
2025-10-14 15:13:01 - root - INFO - Total training samples: 500
2025-10-14 15:13:01 - root - INFO - 
======================================================================
2025-10-14 15:13:01 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 15:13:01 - root - INFO - ======================================================================
2025-10-14 15:13:01 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 15:13:01 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 15:13:01 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 15:13:02 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:13:02 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:13:02 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:13:03 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 15:13:03 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 15:14:55 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:14:55 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:14:55 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:14:56 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:14:56 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:14:56 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:14:56 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:14:56 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:14:56 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:15:03 - root - INFO - 
======================================================================
2025-10-14 15:15:03 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-14 15:15:03 - root - INFO - ======================================================================
2025-10-14 15:15:03 - root - INFO - Final Training Loss: 1.1637
2025-10-14 15:15:03 - root - INFO - Final Log Posterior: -19766.3381
2025-10-14 15:15:03 - root - INFO - 
Evaluation Results:
2025-10-14 15:15:03 - root - INFO -   Deterministic Loss: 0.5423
2025-10-14 15:15:03 - root - INFO -   Bayesian Loss: 0.5421
2025-10-14 15:15:03 - root - INFO -   Improvement: +0.0001
2025-10-14 15:15:03 - root - INFO -   Better than deterministic: True
2025-10-14 15:15:03 - root - INFO - ======================================================================
2025-10-14 15:15:03 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-14 15:15:03 - root - INFO - ======================================================================
2025-10-14 15:21:47 - root - INFO - ======================================================================
2025-10-14 15:21:47 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 15:21:47 - root - INFO - ======================================================================
2025-10-14 15:21:47 - root - INFO - Sampler: VI
2025-10-14 15:21:47 - root - INFO - Log file: logs/vi_training.log
2025-10-14 15:21:47 - root - INFO - Using W&B: True
2025-10-14 15:21:47 - root - INFO - ======================================================================
2025-10-14 15:21:47 - root - INFO - Random seed set to: 42
2025-10-14 15:21:47 - root - INFO - 
======================================================================
2025-10-14 15:21:47 - root - INFO - Loading pre-trained model...
2025-10-14 15:21:47 - root - INFO - ======================================================================
2025-10-14 15:21:47 - root - INFO - Model loaded successfully!
2025-10-14 15:21:47 - root - INFO - Vocabulary size: 65
2025-10-14 15:21:47 - root - INFO - 
======================================================================
2025-10-14 15:21:47 - root - INFO - Preparing training data...
2025-10-14 15:21:47 - root - INFO - ======================================================================
2025-10-14 15:21:47 - root - INFO - Created 32 training batches
2025-10-14 15:21:47 - root - INFO - Batch shape: torch.Size([16, 128])
2025-10-14 15:21:47 - root - INFO - Target shape: torch.Size([16, 1])
2025-10-14 15:21:47 - root - INFO - Total training samples: 500
2025-10-14 15:21:47 - root - INFO - 
======================================================================
2025-10-14 15:21:47 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 15:21:47 - root - INFO - ======================================================================
2025-10-14 15:21:47 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 15:21:47 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 15:21:47 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 15:21:47 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:21:48 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:21:48 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:21:49 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 15:21:49 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 15:23:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:23:42 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:23:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:23:42 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:23:42 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:23:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:23:43 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:23:43 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 15:23:43 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 15:23:50 - root - INFO - 
======================================================================
2025-10-14 15:23:50 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-14 15:23:50 - root - INFO - ======================================================================
2025-10-14 15:23:50 - root - INFO - Final Training Loss: 1.1637
2025-10-14 15:23:50 - root - INFO - Final Log Posterior: -19766.3381
2025-10-14 15:23:50 - root - INFO - 
Evaluation Results:
2025-10-14 15:23:50 - root - INFO -   Deterministic Loss: 0.5423
2025-10-14 15:23:50 - root - INFO -   Bayesian Loss: 0.5421
2025-10-14 15:23:50 - root - INFO -   Improvement: +0.0001
2025-10-14 15:23:50 - root - INFO -   Better than deterministic: True
2025-10-14 15:23:50 - root - INFO - ======================================================================
2025-10-14 15:23:50 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-14 15:23:50 - root - INFO - ======================================================================
2025-10-14 16:57:43 - root - INFO - ======================================================================
2025-10-14 16:57:43 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 16:57:43 - root - INFO - ======================================================================
2025-10-14 16:57:43 - root - INFO - Sampler: VI
2025-10-14 16:57:43 - root - INFO - Log file: logs/vi_training.log
2025-10-14 16:57:43 - root - INFO - Using W&B: True
2025-10-14 16:57:43 - root - INFO - ======================================================================
2025-10-14 16:57:43 - root - INFO - Random seed set to: 42
2025-10-14 16:57:43 - root - INFO - 
======================================================================
2025-10-14 16:57:43 - root - INFO - Loading pre-trained model...
2025-10-14 16:57:43 - root - INFO - ======================================================================
2025-10-14 16:57:43 - root - INFO - Model loaded successfully!
2025-10-14 16:57:43 - root - INFO - Vocabulary size: 65
2025-10-14 16:57:43 - root - INFO - 
======================================================================
2025-10-14 16:57:43 - root - INFO - Preparing training data...
2025-10-14 16:57:43 - root - INFO - ======================================================================
2025-10-14 16:57:43 - root - INFO - Created 32 training batches
2025-10-14 16:57:43 - root - INFO - Batch shape: torch.Size([16, 128])
2025-10-14 16:57:43 - root - INFO - Target shape: torch.Size([16, 1])
2025-10-14 16:57:43 - root - INFO - Total training samples: 500
2025-10-14 16:57:43 - root - INFO - 
======================================================================
2025-10-14 16:57:43 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 16:57:43 - root - INFO - ======================================================================
2025-10-14 16:57:43 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 16:57:43 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 16:57:43 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 16:57:43 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 16:57:44 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 16:57:44 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 16:57:45 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 16:57:45 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 16:59:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 16:59:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 16:59:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 16:59:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 16:59:14 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 16:59:14 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 16:59:14 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 16:59:14 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 16:59:14 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 16:59:21 - root - INFO - 
======================================================================
2025-10-14 16:59:21 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-14 16:59:21 - root - INFO - ======================================================================
2025-10-14 16:59:21 - root - INFO - Final Training Loss: 1.1638
2025-10-14 16:59:21 - root - INFO - Final Log Posterior: -91198.3491
2025-10-14 16:59:21 - root - INFO - 
Evaluation Results:
2025-10-14 16:59:21 - root - INFO -   Deterministic Loss: 0.5423
2025-10-14 16:59:21 - root - INFO -   Bayesian Loss: 0.5421
2025-10-14 16:59:21 - root - INFO -   Improvement: +0.0001
2025-10-14 16:59:21 - root - INFO -   Better than deterministic: True
2025-10-14 16:59:21 - root - INFO - ======================================================================
2025-10-14 16:59:21 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-14 16:59:21 - root - INFO - ======================================================================
2025-10-14 17:07:04 - root - INFO - ======================================================================
2025-10-14 17:07:04 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 17:07:04 - root - INFO - ======================================================================
2025-10-14 17:07:04 - root - INFO - Sampler: VI
2025-10-14 17:07:04 - root - INFO - Log file: logs/vi_training.log
2025-10-14 17:07:04 - root - INFO - Using W&B: True
2025-10-14 17:07:04 - root - INFO - ======================================================================
2025-10-14 17:07:04 - root - INFO - Random seed set to: 42
2025-10-14 17:07:04 - root - INFO - 
======================================================================
2025-10-14 17:07:04 - root - INFO - Loading pre-trained model...
2025-10-14 17:07:04 - root - INFO - ======================================================================
2025-10-14 17:07:04 - root - INFO - Model loaded successfully!
2025-10-14 17:07:04 - root - INFO - Vocabulary size: 65
2025-10-14 17:07:04 - root - INFO - 
======================================================================
2025-10-14 17:07:04 - root - INFO - Preparing training data...
2025-10-14 17:07:04 - root - INFO - ======================================================================
2025-10-14 17:07:05 - root - INFO - Created 63 training batches
2025-10-14 17:07:05 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-14 17:07:05 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-14 17:07:05 - root - INFO - Total training samples: 2000
2025-10-14 17:07:05 - root - INFO - 
======================================================================
2025-10-14 17:07:05 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 17:07:05 - root - INFO - ======================================================================
2025-10-14 17:07:05 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 17:07:05 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 17:07:05 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 17:07:05 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 17:07:05 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:07:05 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:07:06 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 17:07:06 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 17:07:58 - root - ERROR - 
======================================================================
2025-10-14 17:07:58 - root - ERROR - TRAINING FAILED!
2025-10-14 17:07:58 - root - ERROR - ======================================================================
2025-10-14 17:07:58 - root - ERROR - 'NoneType' object has no attribute 'items'
Traceback (most recent call last):
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/scripts/bayesian_training_script.py", line 200, in main
    state, metrics, eval_results = run_bayesian_pipeline(
                                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 712, in run_bayesian_pipeline
    save_dir = pipeline.save_model(state, MODEL, eval_results)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 559, in save_model
    for k, v in state.aux.items()} if hasattr(state, 'aux') else {},
                ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'items'
2025-10-14 17:10:18 - root - INFO - ======================================================================
2025-10-14 17:10:18 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 17:10:18 - root - INFO - ======================================================================
2025-10-14 17:10:18 - root - INFO - Sampler: VI
2025-10-14 17:10:18 - root - INFO - Log file: logs/vi_training.log
2025-10-14 17:10:18 - root - INFO - Using W&B: True
2025-10-14 17:10:18 - root - INFO - ======================================================================
2025-10-14 17:10:18 - root - INFO - Random seed set to: 42
2025-10-14 17:10:18 - root - INFO - 
======================================================================
2025-10-14 17:10:18 - root - INFO - Loading pre-trained model...
2025-10-14 17:10:18 - root - INFO - ======================================================================
2025-10-14 17:10:19 - root - INFO - Model loaded successfully!
2025-10-14 17:10:19 - root - INFO - Vocabulary size: 65
2025-10-14 17:10:19 - root - INFO - 
======================================================================
2025-10-14 17:10:19 - root - INFO - Preparing training data...
2025-10-14 17:10:19 - root - INFO - ======================================================================
2025-10-14 17:10:19 - root - INFO - Created 63 training batches
2025-10-14 17:10:19 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-14 17:10:19 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-14 17:10:19 - root - INFO - Total training samples: 2000
2025-10-14 17:10:19 - root - INFO - 
======================================================================
2025-10-14 17:10:19 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 17:10:19 - root - INFO - ======================================================================
2025-10-14 17:10:19 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 17:10:19 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 17:10:19 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 17:10:19 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 17:10:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.wandb.ai:443
2025-10-14 17:10:29 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:10:29 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:10:29 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:10:29 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:10:30 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 17:10:30 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 17:11:21 - root - ERROR - 
======================================================================
2025-10-14 17:11:21 - root - ERROR - TRAINING FAILED!
2025-10-14 17:11:21 - root - ERROR - ======================================================================
2025-10-14 17:11:21 - root - ERROR - 'NoneType' object has no attribute 'items'
Traceback (most recent call last):
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/scripts/bayesian_training_script.py", line 200, in main
    state, metrics, eval_results = run_bayesian_pipeline(
                                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 712, in run_bayesian_pipeline
    save_dir = pipeline.save_model(state, MODEL, eval_results)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 559, in save_model
    for k, v in state.aux.items()} if hasattr(state, 'aux') else {},
                ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'items'
2025-10-14 17:13:37 - root - INFO - ======================================================================
2025-10-14 17:13:37 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 17:13:37 - root - INFO - ======================================================================
2025-10-14 17:13:37 - root - INFO - Sampler: VI
2025-10-14 17:13:37 - root - INFO - Log file: logs/vi_training.log
2025-10-14 17:13:37 - root - INFO - Using W&B: True
2025-10-14 17:13:37 - root - INFO - ======================================================================
2025-10-14 17:13:37 - root - INFO - Random seed set to: 42
2025-10-14 17:13:37 - root - INFO - 
======================================================================
2025-10-14 17:13:37 - root - INFO - Loading pre-trained model...
2025-10-14 17:13:37 - root - INFO - ======================================================================
2025-10-14 17:13:37 - root - INFO - Model loaded successfully!
2025-10-14 17:13:37 - root - INFO - Vocabulary size: 65
2025-10-14 17:13:37 - root - INFO - 
======================================================================
2025-10-14 17:13:37 - root - INFO - Preparing training data...
2025-10-14 17:13:37 - root - INFO - ======================================================================
2025-10-14 17:13:38 - root - INFO - Created 63 training batches
2025-10-14 17:13:38 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-14 17:13:38 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-14 17:13:38 - root - INFO - Total training samples: 2000
2025-10-14 17:13:38 - root - INFO - 
======================================================================
2025-10-14 17:13:38 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 17:13:38 - root - INFO - ======================================================================
2025-10-14 17:13:38 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 17:13:38 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 17:13:38 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 17:13:38 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 17:13:38 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:13:38 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 17:13:38 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 17:13:38 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 18:01:38 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 18:01:58 - root - INFO - 
======================================================================
2025-10-14 18:01:58 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-14 18:01:58 - root - INFO - ======================================================================
2025-10-14 18:01:58 - root - INFO - Final Training Loss: 1.2620
2025-10-14 18:01:58 - root - INFO - Final Log Posterior: -4208245.4762
2025-10-14 18:01:58 - root - INFO - 
Evaluation Results:
2025-10-14 18:01:58 - root - INFO -   Deterministic Loss: 0.5185
2025-10-14 18:01:58 - root - INFO -   Bayesian Loss: 0.5168
2025-10-14 18:01:58 - root - INFO -   Improvement: +0.0018
2025-10-14 18:01:58 - root - INFO -   Better than deterministic: True
2025-10-14 18:01:58 - root - INFO - ======================================================================
2025-10-14 18:01:58 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-14 18:01:58 - root - INFO - ======================================================================
2025-10-14 18:06:56 - root - INFO - ======================================================================
2025-10-14 18:06:56 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 18:06:56 - root - INFO - ======================================================================
2025-10-14 18:06:56 - root - INFO - Sampler: VI
2025-10-14 18:06:56 - root - INFO - Log file: logs/vi_training.log
2025-10-14 18:06:56 - root - INFO - Using W&B: True
2025-10-14 18:06:56 - root - INFO - ======================================================================
2025-10-14 18:06:56 - root - INFO - Random seed set to: 42
2025-10-14 18:06:56 - root - INFO - 
======================================================================
2025-10-14 18:06:56 - root - INFO - Loading pre-trained model...
2025-10-14 18:06:56 - root - INFO - ======================================================================
2025-10-14 18:06:56 - root - INFO - Model loaded successfully!
2025-10-14 18:06:56 - root - INFO - Vocabulary size: 65
2025-10-14 18:06:56 - root - INFO - 
======================================================================
2025-10-14 18:06:56 - root - INFO - Preparing training data...
2025-10-14 18:06:56 - root - INFO - ======================================================================
2025-10-14 18:06:56 - root - INFO - Created 63 training batches
2025-10-14 18:06:56 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-14 18:06:56 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-14 18:06:56 - root - INFO - Total training samples: 2000
2025-10-14 18:06:56 - root - INFO - 
======================================================================
2025-10-14 18:06:56 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 18:06:56 - root - INFO - ======================================================================
2025-10-14 18:06:56 - root - ERROR - 
======================================================================
2025-10-14 18:06:56 - root - ERROR - TRAINING FAILED!
2025-10-14 18:06:56 - root - ERROR - ======================================================================
2025-10-14 18:06:56 - root - ERROR - too many values to unpack (expected 2)
Traceback (most recent call last):
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/scripts/bayesian_training_script.py", line 200, in main
    state, metrics, eval_results = run_bayesian_pipeline(
                                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 693, in run_bayesian_pipeline
    params = {k: v.clone().to(DEVICE) for k, v in dict(MODEL.named_parameters())}
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 693, in <dictcomp>
    params = {k: v.clone().to(DEVICE) for k, v in dict(MODEL.named_parameters())}
                                          ^^^^
ValueError: too many values to unpack (expected 2)
2025-10-14 18:07:49 - root - INFO - ======================================================================
2025-10-14 18:07:49 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 18:07:49 - root - INFO - ======================================================================
2025-10-14 18:07:49 - root - INFO - Sampler: VI
2025-10-14 18:07:49 - root - INFO - Log file: logs/vi_training.log
2025-10-14 18:07:49 - root - INFO - Using W&B: True
2025-10-14 18:07:49 - root - INFO - ======================================================================
2025-10-14 18:07:49 - root - INFO - Random seed set to: 42
2025-10-14 18:07:49 - root - INFO - 
======================================================================
2025-10-14 18:07:49 - root - INFO - Loading pre-trained model...
2025-10-14 18:07:49 - root - INFO - ======================================================================
2025-10-14 18:07:49 - root - INFO - Model loaded successfully!
2025-10-14 18:07:49 - root - INFO - Vocabulary size: 65
2025-10-14 18:07:49 - root - INFO - 
======================================================================
2025-10-14 18:07:49 - root - INFO - Preparing training data...
2025-10-14 18:07:49 - root - INFO - ======================================================================
2025-10-14 18:07:50 - root - INFO - Created 63 training batches
2025-10-14 18:07:50 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-14 18:07:50 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-14 18:07:50 - root - INFO - Total training samples: 2000
2025-10-14 18:07:50 - root - INFO - 
======================================================================
2025-10-14 18:07:50 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 18:07:50 - root - INFO - ======================================================================
2025-10-14 18:07:50 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 18:07:50 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 18:07:50 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 18:07:50 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 18:07:50 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:07:50 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:07:50 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 18:07:50 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 18:09:18 - root - ERROR - 
======================================================================
2025-10-14 18:09:18 - root - ERROR - TRAINING FAILED!
2025-10-14 18:09:18 - root - ERROR - ======================================================================
2025-10-14 18:09:18 - root - ERROR - 'NoneType' object has no attribute 'items'
Traceback (most recent call last):
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/scripts/bayesian_training_script.py", line 200, in main
    state, metrics, eval_results = run_bayesian_pipeline(
                                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 713, in run_bayesian_pipeline
    save_dir = pipeline.save_model(state, MODEL, eval_results)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 560, in save_model
    for k, v in state.aux.items()} if hasattr(state, 'aux') else {},
                ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'items'
2025-10-14 18:09:28 - root - INFO - ======================================================================
2025-10-14 18:09:28 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-14 18:09:28 - root - INFO - ======================================================================
2025-10-14 18:09:28 - root - INFO - Sampler: VI
2025-10-14 18:09:28 - root - INFO - Log file: logs/vi_training.log
2025-10-14 18:09:28 - root - INFO - Using W&B: True
2025-10-14 18:09:28 - root - INFO - ======================================================================
2025-10-14 18:09:28 - root - INFO - Random seed set to: 42
2025-10-14 18:09:28 - root - INFO - 
======================================================================
2025-10-14 18:09:28 - root - INFO - Loading pre-trained model...
2025-10-14 18:09:28 - root - INFO - ======================================================================
2025-10-14 18:09:28 - root - INFO - Model loaded successfully!
2025-10-14 18:09:28 - root - INFO - Vocabulary size: 65
2025-10-14 18:09:28 - root - INFO - 
======================================================================
2025-10-14 18:09:28 - root - INFO - Preparing training data...
2025-10-14 18:09:28 - root - INFO - ======================================================================
2025-10-14 18:09:28 - root - INFO - Created 63 training batches
2025-10-14 18:09:28 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-14 18:09:28 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-14 18:09:28 - root - INFO - Total training samples: 2000
2025-10-14 18:09:28 - root - INFO - 
======================================================================
2025-10-14 18:09:28 - root - INFO - Starting Bayesian training pipeline...
2025-10-14 18:09:28 - root - INFO - ======================================================================
2025-10-14 18:09:28 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-14 18:09:28 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 18:09:28 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-14 18:09:28 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 18:09:28 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:09:29 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:09:29 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-14 18:09:29 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-14 18:18:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 18:18:24 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:18:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 18:18:24 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:18:25 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:18:25 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 18:18:25 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:18:25 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-14 18:18:25 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-14 18:18:32 - root - INFO - 
======================================================================
2025-10-14 18:18:32 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-14 18:18:32 - root - INFO - ======================================================================
2025-10-14 18:18:32 - root - INFO - Final Training Loss: 1.2613
2025-10-14 18:18:32 - root - INFO - Final Log Posterior: 7432.4463
2025-10-14 18:18:32 - root - INFO - 
Evaluation Results:
2025-10-14 18:18:32 - root - INFO -   Deterministic Loss: 0.5185
2025-10-14 18:18:32 - root - INFO -   Bayesian Loss: 0.5188
2025-10-14 18:18:32 - root - INFO -   Improvement: -0.0003
2025-10-14 18:18:32 - root - INFO -   Better than deterministic: False
2025-10-14 18:18:32 - root - INFO - ======================================================================
2025-10-14 18:18:32 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-14 18:18:32 - root - INFO - ======================================================================
2025-10-15 17:02:46 - root - INFO - ======================================================================
2025-10-15 17:02:46 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:02:46 - root - INFO - ======================================================================
2025-10-15 17:02:46 - root - INFO - Sampler: VI
2025-10-15 17:02:46 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:02:46 - root - INFO - Using W&B: True
2025-10-15 17:02:46 - root - INFO - ======================================================================
2025-10-15 17:02:46 - root - INFO - Random seed set to: 42
2025-10-15 17:02:46 - root - INFO - 
======================================================================
2025-10-15 17:02:46 - root - INFO - Loading pre-trained model...
2025-10-15 17:02:46 - root - INFO - ======================================================================
2025-10-15 17:02:46 - root - INFO - Model loaded successfully!
2025-10-15 17:02:46 - root - INFO - Vocabulary size: 65
2025-10-15 17:02:46 - root - INFO - 
======================================================================
2025-10-15 17:02:46 - root - INFO - Preparing training data...
2025-10-15 17:02:46 - root - INFO - ======================================================================
2025-10-15 17:02:46 - root - INFO - Created 63 training batches
2025-10-15 17:02:46 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:02:46 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:02:46 - root - INFO - Total training samples: 2000
2025-10-15 17:02:46 - root - INFO - 
======================================================================
2025-10-15 17:02:46 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:02:46 - root - INFO - ======================================================================
2025-10-15 17:02:46 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:02:46 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:02:46 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:02:46 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:02:47 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:02:47 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:02:48 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:02:48 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:02:50 - root - ERROR - 
======================================================================
2025-10-15 17:02:50 - root - ERROR - TRAINING FAILED!
2025-10-15 17:02:50 - root - ERROR - ======================================================================
2025-10-15 17:02:50 - root - ERROR - build() got an unexpected keyword argument 'init_log_scale'
Traceback (most recent call last):
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/scripts/bayesian_training_script.py", line 200, in main
    state, metrics, eval_results = run_bayesian_pipeline(
                                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 709, in run_bayesian_pipeline
    transform, state = pipeline.setup_sampler(log_posterior_fn, params)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 168, in setup_sampler
    return self._setup_vi(log_posterior_fn, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 181, in _setup_vi
    transform = posteriors.vi.diag.build(
                ^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: build() got an unexpected keyword argument 'init_log_scale'
2025-10-15 17:11:51 - root - INFO - ======================================================================
2025-10-15 17:11:51 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:11:51 - root - INFO - ======================================================================
2025-10-15 17:11:51 - root - INFO - Sampler: VI
2025-10-15 17:11:51 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:11:51 - root - INFO - Using W&B: True
2025-10-15 17:11:51 - root - INFO - ======================================================================
2025-10-15 17:11:51 - root - INFO - Random seed set to: 42
2025-10-15 17:11:51 - root - INFO - 
======================================================================
2025-10-15 17:11:51 - root - INFO - Loading pre-trained model...
2025-10-15 17:11:51 - root - INFO - ======================================================================
2025-10-15 17:11:51 - root - INFO - Model loaded successfully!
2025-10-15 17:11:51 - root - INFO - Vocabulary size: 65
2025-10-15 17:11:51 - root - INFO - 
======================================================================
2025-10-15 17:11:51 - root - INFO - Preparing training data...
2025-10-15 17:11:51 - root - INFO - ======================================================================
2025-10-15 17:11:51 - root - INFO - Created 63 training batches
2025-10-15 17:11:51 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:11:51 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:11:51 - root - INFO - Total training samples: 2000
2025-10-15 17:11:51 - root - INFO - 
======================================================================
2025-10-15 17:11:51 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:11:51 - root - INFO - ======================================================================
2025-10-15 17:11:51 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:11:51 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:11:51 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:11:52 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:11:52 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:11:52 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:11:53 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:11:53 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:20:12 - root - INFO - ======================================================================
2025-10-15 17:20:12 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:20:12 - root - INFO - ======================================================================
2025-10-15 17:20:12 - root - INFO - Sampler: VI
2025-10-15 17:20:12 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:20:12 - root - INFO - Using W&B: True
2025-10-15 17:20:12 - root - INFO - ======================================================================
2025-10-15 17:20:12 - root - INFO - Random seed set to: 42
2025-10-15 17:20:12 - root - INFO - 
======================================================================
2025-10-15 17:20:12 - root - INFO - Loading pre-trained model...
2025-10-15 17:20:12 - root - INFO - ======================================================================
2025-10-15 17:20:12 - root - INFO - Model loaded successfully!
2025-10-15 17:20:12 - root - INFO - Vocabulary size: 65
2025-10-15 17:20:12 - root - INFO - 
======================================================================
2025-10-15 17:20:12 - root - INFO - Preparing training data...
2025-10-15 17:20:12 - root - INFO - ======================================================================
2025-10-15 17:20:12 - root - INFO - Created 63 training batches
2025-10-15 17:20:12 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:20:12 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:20:12 - root - INFO - Total training samples: 2000
2025-10-15 17:20:12 - root - INFO - 
======================================================================
2025-10-15 17:20:12 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:20:12 - root - INFO - ======================================================================
2025-10-15 17:20:12 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:20:12 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:20:12 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:20:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:20:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:20:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:20:14 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:20:14 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:23:15 - root - INFO - ======================================================================
2025-10-15 17:23:15 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:23:15 - root - INFO - ======================================================================
2025-10-15 17:23:15 - root - INFO - Sampler: VI
2025-10-15 17:23:15 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:23:15 - root - INFO - Using W&B: True
2025-10-15 17:23:15 - root - INFO - ======================================================================
2025-10-15 17:23:15 - root - INFO - Random seed set to: 42
2025-10-15 17:23:15 - root - INFO - 
======================================================================
2025-10-15 17:23:15 - root - INFO - Loading pre-trained model...
2025-10-15 17:23:15 - root - INFO - ======================================================================
2025-10-15 17:23:16 - root - INFO - Model loaded successfully!
2025-10-15 17:23:16 - root - INFO - Vocabulary size: 65
2025-10-15 17:23:16 - root - INFO - 
======================================================================
2025-10-15 17:23:16 - root - INFO - Preparing training data...
2025-10-15 17:23:16 - root - INFO - ======================================================================
2025-10-15 17:23:16 - root - INFO - Created 63 training batches
2025-10-15 17:23:16 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:23:16 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:23:16 - root - INFO - Total training samples: 2000
2025-10-15 17:23:16 - root - INFO - 
======================================================================
2025-10-15 17:23:16 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:23:16 - root - INFO - ======================================================================
2025-10-15 17:23:16 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:23:16 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:23:16 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:23:16 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:23:16 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:23:17 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:23:17 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:23:17 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:26:17 - root - INFO - ======================================================================
2025-10-15 17:26:17 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:26:17 - root - INFO - ======================================================================
2025-10-15 17:26:17 - root - INFO - Sampler: VI
2025-10-15 17:26:17 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:26:17 - root - INFO - Using W&B: True
2025-10-15 17:26:17 - root - INFO - ======================================================================
2025-10-15 17:26:17 - root - INFO - Random seed set to: 42
2025-10-15 17:26:17 - root - INFO - 
======================================================================
2025-10-15 17:26:17 - root - INFO - Loading pre-trained model...
2025-10-15 17:26:17 - root - INFO - ======================================================================
2025-10-15 17:26:18 - root - INFO - Model loaded successfully!
2025-10-15 17:26:18 - root - INFO - Vocabulary size: 65
2025-10-15 17:26:18 - root - INFO - 
======================================================================
2025-10-15 17:26:18 - root - INFO - Preparing training data...
2025-10-15 17:26:18 - root - INFO - ======================================================================
2025-10-15 17:26:18 - root - INFO - Created 63 training batches
2025-10-15 17:26:18 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:26:18 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:26:18 - root - INFO - Total training samples: 2000
2025-10-15 17:26:18 - root - INFO - 
======================================================================
2025-10-15 17:26:18 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:26:18 - root - INFO - ======================================================================
2025-10-15 17:26:18 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:26:18 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:26:18 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:26:18 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:26:19 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:26:19 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:26:20 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:26:20 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:36:12 - root - INFO - ======================================================================
2025-10-15 17:36:12 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:36:12 - root - INFO - ======================================================================
2025-10-15 17:36:12 - root - INFO - Sampler: VI
2025-10-15 17:36:12 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:36:12 - root - INFO - Using W&B: True
2025-10-15 17:36:12 - root - INFO - ======================================================================
2025-10-15 17:36:12 - root - INFO - Random seed set to: 42
2025-10-15 17:36:12 - root - INFO - 
======================================================================
2025-10-15 17:36:12 - root - INFO - Loading pre-trained model...
2025-10-15 17:36:12 - root - INFO - ======================================================================
2025-10-15 17:36:13 - root - INFO - Model loaded successfully!
2025-10-15 17:36:13 - root - INFO - Vocabulary size: 65
2025-10-15 17:36:13 - root - INFO - 
======================================================================
2025-10-15 17:36:13 - root - INFO - Preparing training data...
2025-10-15 17:36:13 - root - INFO - ======================================================================
2025-10-15 17:36:13 - root - INFO - Created 63 training batches
2025-10-15 17:36:13 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:36:13 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:36:13 - root - INFO - Total training samples: 2000
2025-10-15 17:36:13 - root - INFO - 
======================================================================
2025-10-15 17:36:13 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:36:13 - root - INFO - ======================================================================
2025-10-15 17:36:13 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:36:13 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:36:13 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:36:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:36:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:36:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:36:14 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:36:14 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:43:47 - root - INFO - ======================================================================
2025-10-15 17:43:47 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:43:47 - root - INFO - ======================================================================
2025-10-15 17:43:47 - root - INFO - Sampler: VI
2025-10-15 17:43:47 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:43:47 - root - INFO - Using W&B: True
2025-10-15 17:43:47 - root - INFO - ======================================================================
2025-10-15 17:43:47 - root - INFO - Random seed set to: 42
2025-10-15 17:43:47 - root - INFO - 
======================================================================
2025-10-15 17:43:47 - root - INFO - Loading pre-trained model...
2025-10-15 17:43:47 - root - INFO - ======================================================================
2025-10-15 17:43:47 - root - INFO - Model loaded successfully!
2025-10-15 17:43:47 - root - INFO - Vocabulary size: 65
2025-10-15 17:43:47 - root - INFO - 
======================================================================
2025-10-15 17:43:47 - root - INFO - Preparing training data...
2025-10-15 17:43:47 - root - INFO - ======================================================================
2025-10-15 17:43:47 - root - INFO - Created 63 training batches
2025-10-15 17:43:47 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:43:47 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:43:47 - root - INFO - Total training samples: 2000
2025-10-15 17:43:47 - root - INFO - 
======================================================================
2025-10-15 17:43:47 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:43:47 - root - INFO - ======================================================================
2025-10-15 17:43:47 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:43:47 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:43:47 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:43:47 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:43:47 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:43:48 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:43:48 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:43:48 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:54:49 - root - INFO - ======================================================================
2025-10-15 17:54:49 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:54:49 - root - INFO - ======================================================================
2025-10-15 17:54:49 - root - INFO - Sampler: VI
2025-10-15 17:54:49 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:54:49 - root - INFO - Using W&B: True
2025-10-15 17:54:49 - root - INFO - ======================================================================
2025-10-15 17:54:49 - root - INFO - Random seed set to: 42
2025-10-15 17:54:49 - root - INFO - 
======================================================================
2025-10-15 17:54:49 - root - INFO - Loading pre-trained model...
2025-10-15 17:54:49 - root - INFO - ======================================================================
2025-10-15 17:54:49 - root - INFO - Model loaded successfully!
2025-10-15 17:54:49 - root - INFO - Vocabulary size: 65
2025-10-15 17:54:49 - root - INFO - 
======================================================================
2025-10-15 17:54:49 - root - INFO - Preparing training data...
2025-10-15 17:54:49 - root - INFO - ======================================================================
2025-10-15 17:54:50 - root - INFO - Created 63 training batches
2025-10-15 17:54:50 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:54:50 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:54:50 - root - INFO - Total training samples: 2000
2025-10-15 17:54:50 - root - INFO - 
======================================================================
2025-10-15 17:54:50 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:54:50 - root - INFO - ======================================================================
2025-10-15 17:54:50 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:54:50 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:54:50 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:54:50 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:54:50 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:54:50 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:54:51 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:54:51 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:57:37 - root - INFO - ======================================================================
2025-10-15 17:57:37 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 17:57:37 - root - INFO - ======================================================================
2025-10-15 17:57:37 - root - INFO - Sampler: VI
2025-10-15 17:57:37 - root - INFO - Log file: logs/vi_training.log
2025-10-15 17:57:37 - root - INFO - Using W&B: True
2025-10-15 17:57:37 - root - INFO - ======================================================================
2025-10-15 17:57:37 - root - INFO - Random seed set to: 42
2025-10-15 17:57:37 - root - INFO - 
======================================================================
2025-10-15 17:57:37 - root - INFO - Loading pre-trained model...
2025-10-15 17:57:37 - root - INFO - ======================================================================
2025-10-15 17:57:37 - root - INFO - Model loaded successfully!
2025-10-15 17:57:37 - root - INFO - Vocabulary size: 65
2025-10-15 17:57:37 - root - INFO - 
======================================================================
2025-10-15 17:57:37 - root - INFO - Preparing training data...
2025-10-15 17:57:37 - root - INFO - ======================================================================
2025-10-15 17:57:37 - root - INFO - Created 63 training batches
2025-10-15 17:57:37 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 17:57:37 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 17:57:37 - root - INFO - Total training samples: 2000
2025-10-15 17:57:37 - root - INFO - 
======================================================================
2025-10-15 17:57:37 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 17:57:37 - root - INFO - ======================================================================
2025-10-15 17:57:37 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 17:57:37 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:57:37 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 17:57:37 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 17:57:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.wandb.ai:443
2025-10-15 17:57:48 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 17:57:48 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 17:57:52 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:57:53 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:57:53 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 17:57:54 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 18:00:33 - root - INFO - ======================================================================
2025-10-15 18:00:33 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-15 18:00:33 - root - INFO - ======================================================================
2025-10-15 18:00:33 - root - INFO - Sampler: VI
2025-10-15 18:00:33 - root - INFO - Log file: logs/vi_training.log
2025-10-15 18:00:33 - root - INFO - Using W&B: True
2025-10-15 18:00:33 - root - INFO - ======================================================================
2025-10-15 18:00:33 - root - INFO - Random seed set to: 42
2025-10-15 18:00:33 - root - INFO - 
======================================================================
2025-10-15 18:00:33 - root - INFO - Loading pre-trained model...
2025-10-15 18:00:33 - root - INFO - ======================================================================
2025-10-15 18:00:33 - root - INFO - Model loaded successfully!
2025-10-15 18:00:33 - root - INFO - Vocabulary size: 65
2025-10-15 18:00:33 - root - INFO - 
======================================================================
2025-10-15 18:00:33 - root - INFO - Preparing training data...
2025-10-15 18:00:33 - root - INFO - ======================================================================
2025-10-15 18:00:33 - root - INFO - Created 63 training batches
2025-10-15 18:00:33 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-15 18:00:33 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-15 18:00:33 - root - INFO - Total training samples: 2000
2025-10-15 18:00:33 - root - INFO - 
======================================================================
2025-10-15 18:00:33 - root - INFO - Starting Bayesian training pipeline...
2025-10-15 18:00:33 - root - INFO - ======================================================================
2025-10-15 18:00:33 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-15 18:00:33 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 18:00:33 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-15 18:00:33 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 18:00:33 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 18:00:33 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 18:00:34 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-15 18:00:34 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-15 21:04:22 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 21:04:22 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 21:04:22 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 21:04:23 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 21:04:23 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 21:04:23 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 21:04:23 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 21:04:23 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-15 21:04:23 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-15 21:04:52 - root - INFO - 
======================================================================
2025-10-15 21:04:52 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-15 21:04:52 - root - INFO - ======================================================================
2025-10-15 21:04:52 - root - INFO - Final Training Loss: 1.3113
2025-10-15 21:04:52 - root - INFO - Final Log Posterior: -29679.8217
2025-10-15 21:04:52 - root - INFO - 
Evaluation Results:
2025-10-15 21:04:52 - root - INFO -   Deterministic Loss: 0.5185
2025-10-15 21:04:52 - root - INFO -   Bayesian Loss: 0.6310
2025-10-15 21:04:52 - root - INFO -   Improvement: -0.1125
2025-10-15 21:04:52 - root - INFO -   Better than deterministic: False
2025-10-15 21:04:52 - root - INFO - ======================================================================
2025-10-15 21:04:52 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-15 21:04:52 - root - INFO - ======================================================================
2025-10-16 09:44:57 - root - INFO - ======================================================================
2025-10-16 09:44:57 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-16 09:44:57 - root - INFO - ======================================================================
2025-10-16 09:44:57 - root - INFO - Sampler: VI
2025-10-16 09:44:57 - root - INFO - Log file: logs/vi_training.log
2025-10-16 09:44:57 - root - INFO - Using W&B: True
2025-10-16 09:44:57 - root - INFO - ======================================================================
2025-10-16 09:44:57 - root - INFO - Random seed set to: 42
2025-10-16 09:44:57 - root - INFO - 
======================================================================
2025-10-16 09:44:57 - root - INFO - Loading pre-trained model...
2025-10-16 09:44:57 - root - INFO - ======================================================================
2025-10-16 09:44:57 - root - INFO - Model loaded successfully!
2025-10-16 09:44:57 - root - INFO - Vocabulary size: 65
2025-10-16 09:44:57 - root - INFO - 
======================================================================
2025-10-16 09:44:57 - root - INFO - Preparing training data...
2025-10-16 09:44:57 - root - INFO - ======================================================================
2025-10-16 09:44:57 - root - INFO - Created 63 training batches
2025-10-16 09:44:57 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-16 09:44:57 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-16 09:44:57 - root - INFO - Total training samples: 2000
2025-10-16 09:44:57 - root - INFO - 
======================================================================
2025-10-16 09:44:57 - root - INFO - Starting Bayesian training pipeline...
2025-10-16 09:44:57 - root - INFO - ======================================================================
2025-10-16 09:44:57 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-16 09:44:57 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 09:44:57 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-16 09:44:57 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 09:44:58 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 09:44:58 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 09:44:59 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 09:44:59 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 10:58:34 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 10:58:35 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 10:59:03 - root - INFO - 
======================================================================
2025-10-16 10:59:03 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-16 10:59:03 - root - INFO - ======================================================================
2025-10-16 10:59:03 - root - INFO - Final Training Loss: 1.3113
2025-10-16 10:59:03 - root - INFO - Final Log Posterior: -1.3110
2025-10-16 10:59:03 - root - INFO - 
Evaluation Results:
2025-10-16 10:59:03 - root - INFO -   Deterministic Loss: 0.5185
2025-10-16 10:59:03 - root - INFO -   Bayesian Loss: 0.6310
2025-10-16 10:59:03 - root - INFO -   Improvement: -0.1125
2025-10-16 10:59:03 - root - INFO -   Better than deterministic: False
2025-10-16 10:59:03 - root - INFO - ======================================================================
2025-10-16 10:59:03 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-16 10:59:03 - root - INFO - ======================================================================
2025-10-16 11:15:12 - root - INFO - ======================================================================
2025-10-16 11:15:12 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-16 11:15:12 - root - INFO - ======================================================================
2025-10-16 11:15:12 - root - INFO - Sampler: VI
2025-10-16 11:15:12 - root - INFO - Log file: logs/vi_training.log
2025-10-16 11:15:12 - root - INFO - Using W&B: True
2025-10-16 11:15:12 - root - INFO - ======================================================================
2025-10-16 11:15:12 - root - INFO - Random seed set to: 42
2025-10-16 11:15:12 - root - INFO - 
======================================================================
2025-10-16 11:15:12 - root - INFO - Loading pre-trained model...
2025-10-16 11:15:12 - root - INFO - ======================================================================
2025-10-16 11:15:13 - root - INFO - Model loaded successfully!
2025-10-16 11:15:13 - root - INFO - Vocabulary size: 65
2025-10-16 11:15:13 - root - INFO - 
======================================================================
2025-10-16 11:15:13 - root - INFO - Preparing training data...
2025-10-16 11:15:13 - root - INFO - ======================================================================
2025-10-16 11:15:13 - root - INFO - Created 63 training batches
2025-10-16 11:15:13 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-16 11:15:13 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-16 11:15:13 - root - INFO - Total training samples: 2000
2025-10-16 11:15:13 - root - INFO - 
======================================================================
2025-10-16 11:15:13 - root - INFO - Starting Bayesian training pipeline...
2025-10-16 11:15:13 - root - INFO - ======================================================================
2025-10-16 11:15:13 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-16 11:15:13 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 11:15:13 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-16 11:15:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 11:15:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 11:15:13 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 11:15:14 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 11:15:14 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-16 12:11:07 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 12:11:08 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 12:11:08 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 12:11:08 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 12:11:08 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 12:11:08 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 12:11:08 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 12:11:08 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 12:11:09 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 12:11:38 - root - INFO - 
======================================================================
2025-10-16 12:11:38 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-16 12:11:38 - root - INFO - ======================================================================
2025-10-16 12:11:38 - root - INFO - Final Training Loss: 1.3108
2025-10-16 12:11:38 - root - INFO - Final Log Posterior: -1.3105
2025-10-16 12:11:38 - root - INFO - 
Evaluation Results:
2025-10-16 12:11:38 - root - INFO -   Deterministic Loss: 0.5185
2025-10-16 12:11:38 - root - INFO -   Bayesian Loss: 0.6351
2025-10-16 12:11:38 - root - INFO -   Improvement: -0.1165
2025-10-16 12:11:38 - root - INFO -   Better than deterministic: False
2025-10-16 12:11:38 - root - INFO - ======================================================================
2025-10-16 12:11:38 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-16 12:11:38 - root - INFO - ======================================================================
2025-10-16 14:56:19 - root - INFO - ======================================================================
2025-10-16 14:56:19 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-16 14:56:19 - root - INFO - ======================================================================
2025-10-16 14:56:19 - root - INFO - Sampler: VI
2025-10-16 14:56:19 - root - INFO - Log file: logs/vi_training.log
2025-10-16 14:56:19 - root - INFO - Using W&B: True
2025-10-16 14:56:19 - root - INFO - ======================================================================
2025-10-16 14:56:19 - root - INFO - Random seed set to: 42
2025-10-16 14:56:19 - root - INFO - 
======================================================================
2025-10-16 14:56:19 - root - INFO - Loading pre-trained model...
2025-10-16 14:56:19 - root - INFO - ======================================================================
2025-10-16 14:56:19 - root - INFO - Model loaded successfully!
2025-10-16 14:56:19 - root - INFO - Vocabulary size: 65
2025-10-16 14:56:19 - root - INFO - 
======================================================================
2025-10-16 14:56:19 - root - INFO - Preparing training data...
2025-10-16 14:56:19 - root - INFO - ======================================================================
2025-10-16 14:56:19 - root - INFO - Created 63 training batches
2025-10-16 14:56:19 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-16 14:56:19 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-16 14:56:19 - root - INFO - Total training samples: 2000
2025-10-16 14:56:19 - root - INFO - 
======================================================================
2025-10-16 14:56:19 - root - INFO - Starting Bayesian training pipeline...
2025-10-16 14:56:19 - root - INFO - ======================================================================
2025-10-16 14:56:19 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-16 14:56:19 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 14:56:19 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-16 14:56:19 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 14:56:19 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 14:56:20 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 14:56:20 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 14:56:20 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-16 15:57:35 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 15:57:35 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 15:57:35 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 15:57:36 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 15:57:36 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 15:57:36 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 15:57:36 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 15:57:36 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 15:57:36 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 15:58:04 - root - INFO - 
======================================================================
2025-10-16 15:58:04 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-16 15:58:04 - root - INFO - ======================================================================
2025-10-16 15:58:04 - root - INFO - Final Training Loss: 1.2627
2025-10-16 15:58:04 - root - INFO - Final Log Posterior: -1.2602
2025-10-16 15:58:04 - root - INFO - 
Evaluation Results:
2025-10-16 15:58:04 - root - INFO -   Deterministic Loss: 0.5185
2025-10-16 15:58:04 - root - INFO -   Bayesian Loss: 0.5313
2025-10-16 15:58:04 - root - INFO -   Improvement: -0.0128
2025-10-16 15:58:04 - root - INFO -   Better than deterministic: False
2025-10-16 15:58:04 - root - INFO - ======================================================================
2025-10-16 15:58:04 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-16 15:58:04 - root - INFO - ======================================================================
2025-10-16 16:05:10 - root - INFO - ======================================================================
2025-10-16 16:05:10 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-16 16:05:10 - root - INFO - ======================================================================
2025-10-16 16:05:10 - root - INFO - Sampler: VI
2025-10-16 16:05:10 - root - INFO - Log file: logs/vi_training.log
2025-10-16 16:05:10 - root - INFO - Using W&B: True
2025-10-16 16:05:10 - root - INFO - ======================================================================
2025-10-16 16:05:10 - root - INFO - Random seed set to: 42
2025-10-16 16:05:10 - root - INFO - 
======================================================================
2025-10-16 16:05:10 - root - INFO - Loading pre-trained model...
2025-10-16 16:05:10 - root - INFO - ======================================================================
2025-10-16 16:05:11 - root - INFO - Model loaded successfully!
2025-10-16 16:05:11 - root - INFO - Vocabulary size: 65
2025-10-16 16:05:11 - root - INFO - 
======================================================================
2025-10-16 16:05:11 - root - INFO - Preparing training data...
2025-10-16 16:05:11 - root - INFO - ======================================================================
2025-10-16 16:05:11 - root - INFO - Created 63 training batches
2025-10-16 16:05:11 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-16 16:05:11 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-16 16:05:11 - root - INFO - Total training samples: 2000
2025-10-16 16:05:11 - root - INFO - 
======================================================================
2025-10-16 16:05:11 - root - INFO - Starting Bayesian training pipeline...
2025-10-16 16:05:11 - root - INFO - ======================================================================
2025-10-16 16:05:11 - asyncio - DEBUG - Using selector: KqueueSelector
2025-10-16 16:05:11 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 16:05:11 - git.cmd - DEBUG - Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=None, shell=False, universal_newlines=False)
2025-10-16 16:05:11 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.wandb.ai:443
2025-10-16 16:05:11 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 16:05:11 - urllib3.connectionpool - DEBUG - https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
2025-10-16 16:05:12 - git.util - DEBUG - sys.platform='darwin', git_executable='git'
2025-10-16 16:05:12 - git.cmd - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen, stdin=<valid stream>, shell=False, universal_newlines=False)
2025-10-16 17:35:42 - root - INFO - 
======================================================================
2025-10-16 17:35:42 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-16 17:35:42 - root - INFO - ======================================================================
2025-10-16 17:35:42 - root - INFO - Final Training Loss: 1.2627
2025-10-16 17:35:42 - root - INFO - Final Log Posterior: -1.3047
2025-10-16 17:35:42 - root - INFO - 
Evaluation Results:
2025-10-16 17:35:42 - root - INFO -   Deterministic Loss: 0.5185
2025-10-16 17:35:42 - root - INFO -   Bayesian Loss: 0.5313
2025-10-16 17:35:42 - root - INFO -   Improvement: -0.0128
2025-10-16 17:35:42 - root - INFO -   Better than deterministic: False
2025-10-16 17:35:42 - root - INFO - ======================================================================
2025-10-16 17:35:42 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-16 17:35:42 - root - INFO - ======================================================================
2025-10-17 00:37:57 - root - INFO - ======================================================================
2025-10-17 00:37:57 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 00:37:57 - root - INFO - ======================================================================
2025-10-17 00:37:57 - root - INFO - Sampler: VI
2025-10-17 00:37:57 - root - INFO - Log file: logs/vi_training.log
2025-10-17 00:37:57 - root - INFO - Using W&B: True
2025-10-17 00:37:57 - root - INFO - ======================================================================
2025-10-17 00:37:58 - root - INFO - Random seed set to: 42
2025-10-17 00:37:58 - root - INFO - 
======================================================================
2025-10-17 00:37:58 - root - INFO - Loading pre-trained model...
2025-10-17 00:37:58 - root - INFO - ======================================================================
2025-10-17 00:37:59 - root - INFO - Model loaded successfully!
2025-10-17 00:37:59 - root - INFO - Vocabulary size: 65
2025-10-17 00:37:59 - root - INFO - 
======================================================================
2025-10-17 00:37:59 - root - INFO - Preparing training data...
2025-10-17 00:37:59 - root - INFO - ======================================================================
2025-10-17 00:37:59 - root - INFO - Created 63 training batches
2025-10-17 00:37:59 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 00:37:59 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 00:37:59 - root - INFO - Total training samples: 2000
2025-10-17 00:37:59 - root - INFO - 
======================================================================
2025-10-17 00:37:59 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 00:37:59 - root - INFO - ======================================================================
2025-10-17 00:45:28 - root - INFO - 
======================================================================
2025-10-17 00:45:28 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-17 00:45:28 - root - INFO - ======================================================================
2025-10-17 00:45:28 - root - INFO - Final Training Loss: 1.2413
2025-10-17 00:45:28 - root - INFO - Final Log Posterior: -1.3099
2025-10-17 00:45:28 - root - INFO - 
Evaluation Results:
2025-10-17 00:45:28 - root - INFO -   Deterministic Loss: 0.5185
2025-10-17 00:45:28 - root - INFO -   Bayesian Loss: 0.5225
2025-10-17 00:45:28 - root - INFO -   Improvement: -0.0040
2025-10-17 00:45:28 - root - INFO -   Better than deterministic: False
2025-10-17 00:45:28 - root - INFO - ======================================================================
2025-10-17 00:45:28 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-17 00:45:28 - root - INFO - ======================================================================
2025-10-17 12:06:55 - root - INFO - ======================================================================
2025-10-17 12:06:55 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 12:06:55 - root - INFO - ======================================================================
2025-10-17 12:06:55 - root - INFO - Sampler: VI
2025-10-17 12:06:55 - root - INFO - Log file: logs/vi_training.log
2025-10-17 12:06:55 - root - INFO - Using W&B: True
2025-10-17 12:06:55 - root - INFO - ======================================================================
2025-10-17 12:06:55 - root - INFO - Random seed set to: 42
2025-10-17 12:06:55 - root - INFO - 
======================================================================
2025-10-17 12:06:55 - root - INFO - Loading pre-trained model...
2025-10-17 12:06:55 - root - INFO - ======================================================================
2025-10-17 12:06:56 - root - INFO - Model loaded successfully!
2025-10-17 12:06:56 - root - INFO - Vocabulary size: 65
2025-10-17 12:06:56 - root - INFO - 
======================================================================
2025-10-17 12:06:56 - root - INFO - Preparing training data...
2025-10-17 12:06:56 - root - INFO - ======================================================================
2025-10-17 12:06:56 - root - INFO - Created 63 training batches
2025-10-17 12:06:56 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 12:06:56 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 12:06:56 - root - INFO - Total training samples: 2000
2025-10-17 12:06:56 - root - INFO - 
======================================================================
2025-10-17 12:06:56 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 12:06:56 - root - INFO - ======================================================================
2025-10-17 12:23:10 - root - INFO - 
======================================================================
2025-10-17 12:23:10 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-17 12:23:10 - root - INFO - ======================================================================
2025-10-17 12:23:10 - root - INFO - Final Training Loss: 1.2546
2025-10-17 12:23:10 - root - INFO - Final Log Posterior: -1.7500
2025-10-17 12:23:10 - root - INFO - 
Evaluation Results:
2025-10-17 12:23:10 - root - INFO -   Deterministic Loss: 0.5185
2025-10-17 12:23:10 - root - INFO -   Bayesian Loss: 0.5219
2025-10-17 12:23:10 - root - INFO -   Improvement: -0.0034
2025-10-17 12:23:10 - root - INFO -   Better than deterministic: False
2025-10-17 12:23:10 - root - INFO - ======================================================================
2025-10-17 12:23:10 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-17 12:23:10 - root - INFO - ======================================================================
2025-10-17 12:58:50 - root - INFO - ======================================================================
2025-10-17 12:58:50 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 12:58:50 - root - INFO - ======================================================================
2025-10-17 12:58:50 - root - INFO - Sampler: VI
2025-10-17 12:58:50 - root - INFO - Log file: logs/vi_training.log
2025-10-17 12:58:50 - root - INFO - Using W&B: True
2025-10-17 12:58:50 - root - INFO - ======================================================================
2025-10-17 12:58:50 - root - INFO - Random seed set to: 42
2025-10-17 12:58:50 - root - INFO - 
======================================================================
2025-10-17 12:58:50 - root - INFO - Loading pre-trained model...
2025-10-17 12:58:50 - root - INFO - ======================================================================
2025-10-17 12:58:50 - root - INFO - Model loaded successfully!
2025-10-17 12:58:50 - root - INFO - Vocabulary size: 65
2025-10-17 12:58:50 - root - INFO - 
======================================================================
2025-10-17 12:58:50 - root - INFO - Preparing training data...
2025-10-17 12:58:50 - root - INFO - ======================================================================
2025-10-17 12:58:50 - root - INFO - Created 63 training batches
2025-10-17 12:58:50 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 12:58:50 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 12:58:50 - root - INFO - Total training samples: 2000
2025-10-17 12:58:50 - root - INFO - 
======================================================================
2025-10-17 12:58:50 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 12:58:50 - root - INFO - ======================================================================
2025-10-17 13:34:20 - root - INFO - 
======================================================================
2025-10-17 13:34:20 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-17 13:34:20 - root - INFO - ======================================================================
2025-10-17 13:34:20 - root - INFO - Final Training Loss: 1.2546
2025-10-17 13:34:20 - root - INFO - Final Log Posterior: -3.7248
2025-10-17 13:34:20 - root - INFO - 
Evaluation Results:
2025-10-17 13:34:20 - root - INFO -   Deterministic Loss: 0.5185
2025-10-17 13:34:20 - root - INFO -   Bayesian Loss: 0.5219
2025-10-17 13:34:20 - root - INFO -   Improvement: -0.0034
2025-10-17 13:34:20 - root - INFO -   Better than deterministic: False
2025-10-17 13:34:20 - root - INFO - ======================================================================
2025-10-17 13:34:20 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-17 13:34:20 - root - INFO - ======================================================================
2025-10-17 13:52:51 - root - INFO - ======================================================================
2025-10-17 13:52:51 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 13:52:51 - root - INFO - ======================================================================
2025-10-17 13:52:51 - root - INFO - Sampler: VI
2025-10-17 13:52:51 - root - INFO - Log file: logs/vi_training.log
2025-10-17 13:52:51 - root - INFO - Using W&B: True
2025-10-17 13:52:51 - root - INFO - ======================================================================
2025-10-17 13:52:51 - root - INFO - Random seed set to: 42
2025-10-17 13:52:51 - root - INFO - 
======================================================================
2025-10-17 13:52:51 - root - INFO - Loading pre-trained model...
2025-10-17 13:52:51 - root - INFO - ======================================================================
2025-10-17 13:52:51 - root - INFO - Model loaded successfully!
2025-10-17 13:52:51 - root - INFO - Vocabulary size: 65
2025-10-17 13:52:51 - root - INFO - 
======================================================================
2025-10-17 13:52:51 - root - INFO - Preparing training data...
2025-10-17 13:52:51 - root - INFO - ======================================================================
2025-10-17 13:52:51 - root - INFO - Created 63 training batches
2025-10-17 13:52:51 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 13:52:51 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 13:52:51 - root - INFO - Total training samples: 2000
2025-10-17 13:52:51 - root - INFO - 
======================================================================
2025-10-17 13:52:51 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 13:52:51 - root - INFO - ======================================================================
2025-10-17 13:52:52 - root - ERROR - 
======================================================================
2025-10-17 13:52:52 - root - ERROR - TRAINING FAILED!
2025-10-17 13:52:52 - root - ERROR - ======================================================================
2025-10-17 13:52:52 - root - ERROR - GradientTransformation is not an Optimizer
Traceback (most recent call last):
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/scripts/bayesian_training_script.py", line 200, in main
    state, metrics, eval_results = run_bayesian_pipeline(
                                   ~~~~~~~~~~~~~~~~~~~~~^
        training_batches,
        ^^^^^^^^^^^^^^^^^
        sampler_type=args.sampler,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
        use_wandb=not args.no_wandb
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 733, in run_bayesian_pipeline
    state, metrics = pipeline.run_training(
                     ~~~~~~~~~~~~~~~~~~~~~^
        transform, state, training_batches,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        single_batch_loss, log_posterior_fn, optimizer=optimizer
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 270, in run_training
    scheduler = CosineAnnealingLR(optimizer, T_max=self.config['num_epochs'])
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/.venv/lib/python3.14/site-packages/torch/optim/lr_scheduler.py", line 1085, in __init__
    super().__init__(optimizer, last_epoch)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/.venv/lib/python3.14/site-packages/torch/optim/lr_scheduler.py", line 95, in __init__
    raise TypeError(f"{type(optimizer).__name__} is not an Optimizer")
TypeError: GradientTransformation is not an Optimizer
2025-10-17 14:00:12 - root - INFO - ======================================================================
2025-10-17 14:00:12 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 14:00:12 - root - INFO - ======================================================================
2025-10-17 14:00:12 - root - INFO - Sampler: VI
2025-10-17 14:00:12 - root - INFO - Log file: logs/vi_training.log
2025-10-17 14:00:12 - root - INFO - Using W&B: True
2025-10-17 14:00:12 - root - INFO - ======================================================================
2025-10-17 14:00:12 - root - INFO - Random seed set to: 42
2025-10-17 14:00:12 - root - INFO - 
======================================================================
2025-10-17 14:00:12 - root - INFO - Loading pre-trained model...
2025-10-17 14:00:12 - root - INFO - ======================================================================
2025-10-17 14:00:12 - root - INFO - Model loaded successfully!
2025-10-17 14:00:12 - root - INFO - Vocabulary size: 65
2025-10-17 14:00:12 - root - INFO - 
======================================================================
2025-10-17 14:00:12 - root - INFO - Preparing training data...
2025-10-17 14:00:12 - root - INFO - ======================================================================
2025-10-17 14:00:12 - root - INFO - Created 63 training batches
2025-10-17 14:00:12 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 14:00:12 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 14:00:12 - root - INFO - Total training samples: 2000
2025-10-17 14:00:12 - root - INFO - 
======================================================================
2025-10-17 14:00:12 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 14:00:12 - root - INFO - ======================================================================
2025-10-17 14:00:12 - root - ERROR - 
======================================================================
2025-10-17 14:00:12 - root - ERROR - TRAINING FAILED!
2025-10-17 14:00:12 - root - ERROR - ======================================================================
2025-10-17 14:00:12 - root - ERROR - module 'torchopt.schedule' has no attribute 'cosine_decay_schedule'
Traceback (most recent call last):
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/scripts/bayesian_training_script.py", line 200, in main
    state, metrics, eval_results = run_bayesian_pipeline(
                                   ~~~~~~~~~~~~~~~~~~~~~^
        training_batches,
        ^^^^^^^^^^^^^^^^^
        sampler_type=args.sampler,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
        use_wandb=not args.no_wandb
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 730, in run_bayesian_pipeline
    transform, state = pipeline.setup_sampler(log_posterior_fn, params)
                       ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 173, in setup_sampler
    return self._setup_vi(log_posterior_fn, params)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sofianikolenko/Downloads/Projects_25/ADL/adl-bnn-textgen/src/bayesian_utils.py", line 189, in _setup_vi
    lr_schedule = torchopt.schedule.cosine_decay_schedule(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'torchopt.schedule' has no attribute 'cosine_decay_schedule'
2025-10-17 14:03:56 - root - INFO - ======================================================================
2025-10-17 14:03:56 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 14:03:56 - root - INFO - ======================================================================
2025-10-17 14:03:56 - root - INFO - Sampler: VI
2025-10-17 14:03:56 - root - INFO - Log file: logs/vi_training.log
2025-10-17 14:03:56 - root - INFO - Using W&B: True
2025-10-17 14:03:56 - root - INFO - ======================================================================
2025-10-17 14:03:56 - root - INFO - Random seed set to: 42
2025-10-17 14:03:56 - root - INFO - 
======================================================================
2025-10-17 14:03:56 - root - INFO - Loading pre-trained model...
2025-10-17 14:03:56 - root - INFO - ======================================================================
2025-10-17 14:03:56 - root - INFO - Model loaded successfully!
2025-10-17 14:03:56 - root - INFO - Vocabulary size: 65
2025-10-17 14:03:56 - root - INFO - 
======================================================================
2025-10-17 14:03:56 - root - INFO - Preparing training data...
2025-10-17 14:03:56 - root - INFO - ======================================================================
2025-10-17 14:03:56 - root - INFO - Created 63 training batches
2025-10-17 14:03:56 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 14:03:56 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 14:03:56 - root - INFO - Total training samples: 2000
2025-10-17 14:03:56 - root - INFO - 
======================================================================
2025-10-17 14:03:56 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 14:03:56 - root - INFO - ======================================================================
2025-10-17 14:16:19 - root - INFO - 
======================================================================
2025-10-17 14:16:19 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-17 14:16:19 - root - INFO - ======================================================================
2025-10-17 14:16:19 - root - INFO - Final Training Loss: 1.2539
2025-10-17 14:16:19 - root - INFO - Final Log Posterior: -3.7237
2025-10-17 14:16:19 - root - INFO - 
Evaluation Results:
2025-10-17 14:16:19 - root - INFO -   Deterministic Loss: 0.5185
2025-10-17 14:16:19 - root - INFO -   Bayesian Loss: 0.5246
2025-10-17 14:16:19 - root - INFO -   Improvement: -0.0061
2025-10-17 14:16:19 - root - INFO -   Better than deterministic: False
2025-10-17 14:16:19 - root - INFO - ======================================================================
2025-10-17 14:16:19 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-17 14:16:19 - root - INFO - ======================================================================
2025-10-17 15:26:36 - root - INFO - ======================================================================
2025-10-17 15:26:36 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 15:26:36 - root - INFO - ======================================================================
2025-10-17 15:26:36 - root - INFO - Sampler: VI
2025-10-17 15:26:36 - root - INFO - Log file: logs/vi_training.log
2025-10-17 15:26:36 - root - INFO - Using W&B: True
2025-10-17 15:26:36 - root - INFO - ======================================================================
2025-10-17 15:26:36 - root - INFO - Random seed set to: 42
2025-10-17 15:26:36 - root - INFO - 
======================================================================
2025-10-17 15:26:36 - root - INFO - Loading pre-trained model...
2025-10-17 15:26:36 - root - INFO - ======================================================================
2025-10-17 15:26:37 - root - INFO - Model loaded successfully!
2025-10-17 15:26:37 - root - INFO - Vocabulary size: 65
2025-10-17 15:26:37 - root - INFO - 
======================================================================
2025-10-17 15:26:37 - root - INFO - Preparing training data...
2025-10-17 15:26:37 - root - INFO - ======================================================================
2025-10-17 15:26:37 - root - INFO - Created 63 training batches
2025-10-17 15:26:37 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 15:26:37 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 15:26:37 - root - INFO - Total training samples: 2000
2025-10-17 15:26:37 - root - INFO - 
======================================================================
2025-10-17 15:26:37 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 15:26:37 - root - INFO - ======================================================================
2025-10-17 16:07:01 - root - INFO - 
======================================================================
2025-10-17 16:07:01 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-17 16:07:01 - root - INFO - ======================================================================
2025-10-17 16:07:01 - root - INFO - Final Training Loss: 1.2672
2025-10-17 16:07:01 - root - INFO - Final Log Posterior: -3.7141
2025-10-17 16:07:01 - root - INFO - 
Evaluation Results:
2025-10-17 16:07:01 - root - INFO -   Deterministic Loss: 0.5185
2025-10-17 16:07:01 - root - INFO -   Bayesian Loss: 0.5209
2025-10-17 16:07:01 - root - INFO -   Improvement: -0.0024
2025-10-17 16:07:01 - root - INFO -   Better than deterministic: False
2025-10-17 16:07:01 - root - INFO - ======================================================================
2025-10-17 16:07:01 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-17 16:07:01 - root - INFO - ======================================================================
2025-10-17 16:23:52 - root - INFO - ======================================================================
2025-10-17 16:23:52 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 16:23:52 - root - INFO - ======================================================================
2025-10-17 16:23:52 - root - INFO - Sampler: VI
2025-10-17 16:23:52 - root - INFO - Log file: logs/vi_training.log
2025-10-17 16:23:52 - root - INFO - Using W&B: True
2025-10-17 16:23:52 - root - INFO - ======================================================================
2025-10-17 16:23:52 - root - INFO - Random seed set to: 42
2025-10-17 16:23:52 - root - INFO - 
======================================================================
2025-10-17 16:23:52 - root - INFO - Loading pre-trained model...
2025-10-17 16:23:52 - root - INFO - ======================================================================
2025-10-17 16:23:53 - root - INFO - Model loaded successfully!
2025-10-17 16:23:53 - root - INFO - Vocabulary size: 65
2025-10-17 16:23:53 - root - INFO - 
======================================================================
2025-10-17 16:23:53 - root - INFO - Preparing training data...
2025-10-17 16:23:53 - root - INFO - ======================================================================
2025-10-17 16:23:53 - root - INFO - Created 63 training batches
2025-10-17 16:23:53 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 16:23:53 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 16:23:53 - root - INFO - Total training samples: 2000
2025-10-17 16:23:53 - root - INFO - 
======================================================================
2025-10-17 16:23:53 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 16:23:53 - root - INFO - ======================================================================
2025-10-17 17:06:31 - root - INFO - 
======================================================================
2025-10-17 17:06:31 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-17 17:06:31 - root - INFO - ======================================================================
2025-10-17 17:06:31 - root - INFO - Final Training Loss: 1.2450
2025-10-17 17:06:31 - root - INFO - Final Log Posterior: -3.7276
2025-10-17 17:06:31 - root - INFO - 
Evaluation Results:
2025-10-17 17:06:31 - root - INFO -   Deterministic Loss: 0.5185
2025-10-17 17:06:31 - root - INFO -   Bayesian Loss: 0.5181
2025-10-17 17:06:31 - root - INFO -   Improvement: +0.0005
2025-10-17 17:06:31 - root - INFO -   Better than deterministic: True
2025-10-17 17:06:31 - root - INFO - ======================================================================
2025-10-17 17:06:31 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-17 17:06:31 - root - INFO - ======================================================================
2025-10-17 22:42:32 - root - INFO - ======================================================================
2025-10-17 22:42:32 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-17 22:42:32 - root - INFO - ======================================================================
2025-10-17 22:42:32 - root - INFO - Sampler: VI
2025-10-17 22:42:32 - root - INFO - Log file: logs/vi_training.log
2025-10-17 22:42:32 - root - INFO - Using W&B: True
2025-10-17 22:42:32 - root - INFO - ======================================================================
2025-10-17 22:42:32 - root - INFO - Random seed set to: 42
2025-10-17 22:42:32 - root - INFO - 
======================================================================
2025-10-17 22:42:32 - root - INFO - Loading pre-trained model...
2025-10-17 22:42:32 - root - INFO - ======================================================================
2025-10-17 22:42:32 - root - INFO - Model loaded successfully!
2025-10-17 22:42:32 - root - INFO - Vocabulary size: 65
2025-10-17 22:42:32 - root - INFO - 
======================================================================
2025-10-17 22:42:32 - root - INFO - Preparing training data...
2025-10-17 22:42:32 - root - INFO - ======================================================================
2025-10-17 22:42:32 - root - INFO - Created 157 training batches
2025-10-17 22:42:32 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-17 22:42:32 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-17 22:42:32 - root - INFO - Total training samples: 5000
2025-10-17 22:42:32 - root - INFO - 
======================================================================
2025-10-17 22:42:32 - root - INFO - Starting Bayesian training pipeline...
2025-10-17 22:42:32 - root - INFO - ======================================================================
2025-10-17 23:58:44 - root - INFO - 
======================================================================
2025-10-17 23:58:44 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-17 23:58:44 - root - INFO - ======================================================================
2025-10-17 23:58:44 - root - INFO - Final Training Loss: 1.2212
2025-10-17 23:58:44 - root - INFO - Final Log Posterior: -2.2043
2025-10-17 23:58:44 - root - INFO - 
Evaluation Results:
2025-10-17 23:58:44 - root - INFO -   Deterministic Loss: 0.5185
2025-10-17 23:58:44 - root - INFO -   Bayesian Loss: 0.5222
2025-10-17 23:58:44 - root - INFO -   Improvement: -0.0036
2025-10-17 23:58:44 - root - INFO -   Better than deterministic: False
2025-10-17 23:58:44 - root - INFO - ======================================================================
2025-10-17 23:58:44 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-17 23:58:44 - root - INFO - ======================================================================
2025-10-18 11:42:29 - root - INFO - ======================================================================
2025-10-18 11:42:29 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-18 11:42:29 - root - INFO - ======================================================================
2025-10-18 11:42:29 - root - INFO - Sampler: VI
2025-10-18 11:42:29 - root - INFO - Log file: logs/vi_training.log
2025-10-18 11:42:29 - root - INFO - Using W&B: True
2025-10-18 11:42:29 - root - INFO - ======================================================================
2025-10-18 11:42:29 - root - INFO - Random seed set to: 42
2025-10-18 11:42:29 - root - INFO - 
======================================================================
2025-10-18 11:42:29 - root - INFO - Loading pre-trained model...
2025-10-18 11:42:29 - root - INFO - ======================================================================
2025-10-18 11:42:29 - root - INFO - Model loaded successfully!
2025-10-18 11:42:29 - root - INFO - Vocabulary size: 65
2025-10-18 11:42:29 - root - INFO - 
======================================================================
2025-10-18 11:42:29 - root - INFO - Preparing training data...
2025-10-18 11:42:29 - root - INFO - ======================================================================
2025-10-18 11:42:30 - root - INFO - Created 157 training batches
2025-10-18 11:42:30 - root - INFO - Batch shape: torch.Size([32, 128])
2025-10-18 11:42:30 - root - INFO - Target shape: torch.Size([32, 1])
2025-10-18 11:42:30 - root - INFO - Total training samples: 5000
2025-10-18 11:42:30 - root - INFO - 
======================================================================
2025-10-18 11:42:30 - root - INFO - Starting Bayesian training pipeline...
2025-10-18 11:42:30 - root - INFO - ======================================================================
2025-10-18 14:11:34 - root - INFO - 
======================================================================
2025-10-18 14:11:34 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-18 14:11:34 - root - INFO - ======================================================================
2025-10-18 14:11:34 - root - INFO - Final Training Loss: 1.2110
2025-10-18 14:11:34 - root - INFO - Final Log Posterior: -2.2054
2025-10-18 14:11:34 - root - INFO - 
Evaluation Results:
2025-10-18 14:11:34 - root - INFO -   Deterministic Loss: 0.5185
2025-10-18 14:11:34 - root - INFO -   Bayesian Loss: 0.5199
2025-10-18 14:11:34 - root - INFO -   Improvement: -0.0014
2025-10-18 14:11:34 - root - INFO -   Better than deterministic: False
2025-10-18 14:11:34 - root - INFO - ======================================================================
2025-10-18 14:11:34 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-18 14:11:34 - root - INFO - ======================================================================
2025-10-18 14:32:50 - root - INFO - ======================================================================
2025-10-18 14:32:50 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-18 14:32:50 - root - INFO - ======================================================================
2025-10-18 14:32:50 - root - INFO - Sampler: VI
2025-10-18 14:32:50 - root - INFO - Log file: logs/vi_training.log
2025-10-18 14:32:50 - root - INFO - Using W&B: True
2025-10-18 14:32:50 - root - INFO - ======================================================================
2025-10-18 14:32:50 - root - INFO - Random seed set to: 42
2025-10-18 14:32:50 - root - INFO - 
======================================================================
2025-10-18 14:32:50 - root - INFO - Loading pre-trained model...
2025-10-18 14:32:50 - root - INFO - ======================================================================
2025-10-18 14:32:51 - root - INFO - Model loaded successfully!
2025-10-18 14:32:51 - root - INFO - Vocabulary size: 65
2025-10-18 14:32:51 - root - INFO - 
======================================================================
2025-10-18 14:32:51 - root - INFO - Preparing training data...
2025-10-18 14:32:51 - root - INFO - ======================================================================
2025-10-18 14:32:53 - root - INFO - Created 313 training batches
2025-10-18 14:32:53 - root - INFO - Batch shape: torch.Size([16, 128])
2025-10-18 14:32:53 - root - INFO - Target shape: torch.Size([16, 1])
2025-10-18 14:32:53 - root - INFO - Total training samples: 5000
2025-10-18 14:32:53 - root - INFO - 
======================================================================
2025-10-18 14:32:53 - root - INFO - Starting Bayesian training pipeline...
2025-10-18 14:32:53 - root - INFO - ======================================================================
2025-10-18 17:00:56 - root - INFO - 
======================================================================
2025-10-18 17:00:56 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-18 17:00:56 - root - INFO - ======================================================================
2025-10-18 17:00:56 - root - INFO - Final Training Loss: 1.2312
2025-10-18 17:00:56 - root - INFO - Final Log Posterior: -2.2101
2025-10-18 17:00:56 - root - INFO - 
Evaluation Results:
2025-10-18 17:00:56 - root - INFO -   Deterministic Loss: 0.5423
2025-10-18 17:00:56 - root - INFO -   Bayesian Loss: 0.5268
2025-10-18 17:00:56 - root - INFO -   Improvement: +0.0154
2025-10-18 17:00:56 - root - INFO -   Better than deterministic: True
2025-10-18 17:00:56 - root - INFO - ======================================================================
2025-10-18 17:00:56 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-18 17:00:56 - root - INFO - ======================================================================
2025-10-18 17:37:30 - root - INFO - ======================================================================
2025-10-18 17:37:30 - root - INFO - BAYESIAN NANOGPT TRAINING
2025-10-18 17:37:30 - root - INFO - ======================================================================
2025-10-18 17:37:30 - root - INFO - Sampler: VI
2025-10-18 17:37:30 - root - INFO - Log file: logs/vi_training.log
2025-10-18 17:37:30 - root - INFO - Using W&B: True
2025-10-18 17:37:30 - root - INFO - ======================================================================
2025-10-18 17:37:30 - root - INFO - Random seed set to: 42
2025-10-18 17:37:30 - root - INFO - 
======================================================================
2025-10-18 17:37:30 - root - INFO - Loading pre-trained model...
2025-10-18 17:37:30 - root - INFO - ======================================================================
2025-10-18 17:37:30 - root - INFO - Model loaded successfully!
2025-10-18 17:37:30 - root - INFO - Vocabulary size: 65
2025-10-18 17:37:30 - root - INFO - 
======================================================================
2025-10-18 17:37:30 - root - INFO - Preparing training data...
2025-10-18 17:37:30 - root - INFO - ======================================================================
2025-10-18 17:37:31 - root - INFO - Created 625 training batches
2025-10-18 17:37:31 - root - INFO - Batch shape: torch.Size([16, 128])
2025-10-18 17:37:31 - root - INFO - Target shape: torch.Size([16, 1])
2025-10-18 17:37:31 - root - INFO - Total training samples: 10000
2025-10-18 17:37:31 - root - INFO - 
======================================================================
2025-10-18 17:37:31 - root - INFO - Starting Bayesian training pipeline...
2025-10-18 17:37:31 - root - INFO - ======================================================================
2025-10-19 02:21:51 - root - INFO - 
======================================================================
2025-10-19 02:21:51 - root - INFO - TRAINING COMPLETED SUCCESSFULLY!
2025-10-19 02:21:51 - root - INFO - ======================================================================
2025-10-19 02:21:51 - root - INFO - Final Training Loss: 1.2412
2025-10-19 02:21:51 - root - INFO - Final Log Posterior: -1.7384
2025-10-19 02:21:51 - root - INFO - 
Evaluation Results:
2025-10-19 02:21:51 - root - INFO -   Deterministic Loss: 0.5423
2025-10-19 02:21:51 - root - INFO -   Bayesian Loss: 0.5254
2025-10-19 02:21:51 - root - INFO -   Improvement: +0.0169
2025-10-19 02:21:51 - root - INFO -   Better than deterministic: True
2025-10-19 02:21:51 - root - INFO - ======================================================================
2025-10-19 02:21:51 - root - INFO - Log file saved to: logs/vi_training.log
2025-10-19 02:21:51 - root - INFO - ======================================================================
